{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep learning project 8DM20 CSMIA</h1>\n",
    "\n",
    "<h4>Group members:</h4>\n",
    "O. Akdag - 0842508 <br>\n",
    "T.P.A. Beishuizen - 0791613 <br>\n",
    "A.S.A. Eskelinen - 1224333 <br>\n",
    "J.H.A. Migchielsen - 0495058 <br>\n",
    "L. van den Wildenberg - 0844697 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atte\\Anaconda2\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "# Import all used packages (unused packages are commented out so far)\n",
    "import os\n",
    "from PIL import Image as PIL_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from sklearn.feature_extraction import image as sklearn_image\n",
    "#matplotlib inline\n",
    "import theano\n",
    "import lasagne\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import cPickle\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Preprocessing</h4>\n",
    "\n",
    "Before every thing can be done, at first the data images have to be read and be made in useable data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function that loads the data\n",
    "def loadData(data_set = 'test', image = '1st_manual'):\n",
    "    \n",
    "    # Check for the correct input\n",
    "    if data_set != 'test' and data_set != 'training':\n",
    "        raise Exception('Not the right data_set file')\n",
    "    if image != '1st_manual' and image != '2nd_manual' and image != 'images' and image != 'mask':\n",
    "        raise Exception('Not the right image file')\n",
    "    if data_set == 'training' and image == '2nd_manual':\n",
    "        raise Exception('File not available')\n",
    "    \n",
    "    # Project and image path\n",
    "    project_path = os.getcwd()\n",
    "    images_path = project_path +  '/8DM20_image_dataset/' + data_set + '/' + image + '/'\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    #Open image for image (20 in total for each of them)\n",
    "    for i in range(1, 21):\n",
    "        \n",
    "        # Find correct image number\n",
    "        image_nr = str(i)\n",
    "        if data_set == 'training':\n",
    "            image_nr = str(20 + i)\n",
    "        elif len(image_nr) == 1:\n",
    "            image_nr = '0' + image_nr\n",
    "            \n",
    "        # Specify path for this image\n",
    "        if image == '1st_manual':\n",
    "            image_path = images_path + image_nr + '_manual1.gif'\n",
    "        elif image == '2nd_manual':\n",
    "            image_path = images_path + image_nr + '_manual2.gif'\n",
    "        elif image == 'images':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '.tif'\n",
    "        elif image == 'mask':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '_mask.gif'\n",
    "        \n",
    "        # Open and append the image to the image list\n",
    "        images.append(PIL_image.open(image_path))\n",
    "        \n",
    "    return images\n",
    "\n",
    "#The function that converts the channels in the images from RGB to gray\n",
    "#and makes matrices from the images\n",
    "def convertImageToMatrix(images):\n",
    "    \n",
    "    image_matrices = []\n",
    "    \n",
    "    for image in images:\n",
    "        image_matrix = np.asarray(image.convert('RGB')) #L\n",
    "        image_matrix = image_matrix[:,:,1]\n",
    "        #print np.shape(image_matrix)\n",
    "        image_matrices.append(image_matrix)\n",
    "        \n",
    "    return image_matrices\n",
    "\n",
    "#The function that prepares the image matrices to the data used for machine learning\n",
    "def prepareMachineLearningData(image_matrix, output_matrix, mask_matrix, kernel_size, mask_removal = 'pixel'):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrix, np.ndarray) and \n",
    "            isinstance(output_matrix, np.ndarray) and \n",
    "            isinstance(mask_matrix, np.ndarray)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if mask_removal != 'pixel' and mask_removal != 'patch':\n",
    "        raise Exception(\"Unknown mask data removal type\")\n",
    "    \n",
    "    if not (image_matrix.shape == output_matrix.shape == mask_matrix.shape):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    if np.unique(mask_matrix).shape[0] != 2:\n",
    "        raise Exception(\"The mask matrix does not consist of only 2 values\")\n",
    "    \n",
    "    #Creates a matrix with all possible patches\n",
    "    all_image_patches = sklearn_image.extract_patches_2d(image_matrix,(kernel_size,kernel_size))\n",
    "    all_image_patches = np.expand_dims(all_image_patches, axis=1)\n",
    "    \n",
    "    if kernel_size % 2 != 0:\n",
    "         # Creates an array with all output\n",
    "        mat_red = (kernel_size - 1) / 2\n",
    "        reduced_output_matrix = output_matrix[ mat_red : -  mat_red,  mat_red : -  mat_red]\n",
    "        complete_output_array = reduced_output_matrix.reshape(-1)\n",
    "\n",
    "        new_mask_matrix = mask_matrix.copy()\n",
    "        \n",
    "        # Makes some additional mask values zero on the edge of the mask\n",
    "        if mask_removal == 'patch':\n",
    "            for i in range(mat_red, mask_matrix.shape[0] -  mat_red + 1):\n",
    "                for j in range(mat_red, mask_matrix.shape[1] -  mat_red + 1):\n",
    "                    if 0 in mask_matrix[i - mat_red : i + mat_red + 1, j - mat_red: j + mat_red + 1]:\n",
    "                        new_mask_matrix[i,j] = 0;\n",
    "        \n",
    "        # Creates an array with all mask locations\n",
    "        reduced_mask_matrix = new_mask_matrix[ mat_red : -  mat_red, mat_red : -  mat_red]\n",
    "        mask_array = reduced_mask_matrix.reshape(-1)\n",
    "    \n",
    "    else:\n",
    "        # Creates an array with all output\n",
    "        mat_red = (kernel_size) / 2\n",
    "        reduced_output_matrix = output_matrix[mat_red - 1: -  mat_red,  mat_red - 1: -  mat_red]\n",
    "        complete_output_array = reduced_output_matrix.reshape(-1)\n",
    "\n",
    "        new_mask_matrix = mask_matrix.copy()\n",
    "        \n",
    "        # Makes some additional mask values zero on the edge of the mask\n",
    "        if mask_removal == 'patch':\n",
    "            for i in range(mat_red - 1, mask_matrix.shape[0] -  mat_red - 1):\n",
    "                for j in range(mat_red - 1, mask_matrix.shape[1] -  mat_red - 1):\n",
    "                    if 0 in mask_matrix[i - mat_red + 1 : i + mat_red + 1, j - mat_red + 1: j + mat_red + 1]:\n",
    "                        new_mask_matrix[i,j] = 0;\n",
    "                     \n",
    "        # Creates an array with all mask locations\n",
    "        reduced_mask_matrix = new_mask_matrix[mat_red - 1: - mat_red, mat_red - 1: - mat_red]\n",
    "        mask_array = reduced_mask_matrix.reshape(-1) \n",
    "\n",
    "    image_patches = []\n",
    "    output_array = []    \n",
    "    \n",
    "    # Reduces the number of patches and output to only the mask values\n",
    "    for i in range(len(mask_array)):\n",
    "        if mask_array[i] != 0:\n",
    "            image_patches.append(all_image_patches[i,:,:])\n",
    "            output_array.append(complete_output_array[i])\n",
    "    \n",
    "    # Return the image patches and the output array\n",
    "    return image_patches, output_array\n",
    "\n",
    "# Prepare multiple images at once\n",
    "def prepareMultipleImages(image_matrices, output_matrices, mask_matrices, kernel_size = 25, mask_removal = 'pixel'):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrices, list) and \n",
    "            isinstance(output_matrices, list) and \n",
    "            isinstance(mask_matrices, list)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if not (len(image_matrices) == len(output_matrices) == len(mask_matrices)):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    image_patches = [] \n",
    "    output_arrays = []\n",
    "    \n",
    "    # Finds the output data per image\n",
    "    for i in range(len(image_matrices)):\n",
    "        new_image_patches, new_output_array = prepareMachineLearningData(image_matrices[i], output_matrices[i], mask_matrices[i], \n",
    "                                                                         kernel_size = kernel_size, mask_removal = mask_removal)\n",
    "        image_patches.append(new_image_patches)\n",
    "        output_arrays.append(new_output_array)\n",
    "        \n",
    "        #Print progress for showing time consumption\n",
    "        print\"Progress: {} %\".format(100*(i+1)/len(image_matrices)),\n",
    "              \n",
    "    return image_patches, output_arrays\n",
    "\n",
    "def createVesselImage(output_array, mask_matrix, kernel_size, mask_removal = \"pixel\"):\n",
    "    #Check if input is correct\n",
    "    if not isinstance(output_array, list) or not isinstance(mask_matrix, np.ndarray) or not isinstance(kernel_size, int):\n",
    "        raise Exception(\"Not the right input variables\")\n",
    "    \n",
    "    if mask_removal != \"pixel\" and mask_removal != 'patch':\n",
    "        raise Exception(\"Unknown mask removal type\")\n",
    "    \n",
    "    #Create an output_matrix for the output array\n",
    "    #output_matrix = np.array(mask_matrix)\n",
    "    output_matrix = np.zeros(mask_matrix.shape)\n",
    "    output_loc = 0\n",
    "    \n",
    "    # Take into account that mask pixels too close to the border are lost due to inability to make patches\n",
    "    edge_corr = int(math.ceil(kernel_size / 2) - 1)\n",
    "    \n",
    "    new_mask_matrix = mask_matrix.copy()\n",
    "    \n",
    "    # Makes some additional mask values zero on the edge of the mask\n",
    "    if mask_removal == 'patch':\n",
    "        for i in range(edge_corr, mask_matrix.shape[0] - edge_corr - 2):\n",
    "            for j in range(edge_corr, mask_matrix.shape[1] - edge_corr - 2):\n",
    "                if 0 in mask_matrix[i - edge_corr  : i + edge_corr + 2, j - edge_corr: j + edge_corr + 2]:\n",
    "                    new_mask_matrix[i,j] = 0;\n",
    "       \n",
    "    # Check every pixel within the mask for a vessel pixel\n",
    "    for i in range(mask_matrix.shape[0] - kernel_size + 1):\n",
    "        for j in range(mask_matrix.shape[1] - kernel_size + 1):\n",
    "            if new_mask_matrix[i + edge_corr, j + edge_corr] == 255:\n",
    "                output_matrix[i + edge_corr, j + edge_corr] = output_array[output_loc]\n",
    "                output_loc += 1\n",
    "                \n",
    "    return output_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are loaded and immediately made into matrices for further computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All test image lists\n",
    "test_manual1_images = loadData('test', '1st_manual')\n",
    "test_manual2_images = loadData('test', '2nd_manual')\n",
    "test_raw_images = loadData('test', 'images')\n",
    "test_mask_images = loadData('test', 'mask')\n",
    "\n",
    "# Making matrices of the test images to work with\n",
    "test_manual1_matrices = convertImageToMatrix(test_manual1_images)\n",
    "test_manual2_matrices = convertImageToMatrix(test_manual2_images)\n",
    "test_raw_matrices = convertImageToMatrix(test_raw_images)\n",
    "test_mask_matrices = convertImageToMatrix(test_mask_images)\n",
    "\n",
    "# All training image lists\n",
    "training_manual1_images = loadData('training', '1st_manual')\n",
    "training_raw_images = loadData('training', 'images')\n",
    "training_mask_images = loadData('training', 'mask')\n",
    "\n",
    "# Making matrices of the training images to work with\n",
    "training_manual1_matrices = convertImageToMatrix(training_manual1_images)\n",
    "training_raw_matrices = convertImageToMatrix(training_raw_images)\n",
    "training_mask_matrices = convertImageToMatrix(training_mask_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20L, 584L, 565L)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAEJCAYAAACDnQJZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwjAMJ0wsDMNw4v8BioCD0ORYctkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaa327b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test_manual1_matrices\n",
    "#print np.shape(test_manual1_matrices)\n",
    "#plt.matshow(test_manual1_matrices[0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrices are then used for further preprocessing to retrieve the suitable data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 50 % Progress: 100 % Progress: 100 %\n"
     ]
    }
   ],
   "source": [
    "#Choose the number of images\n",
    "nr_images_training = 2\n",
    "nr_images_test = 1\n",
    "\n",
    "# Prepares the data for machine learning: X = image_patches, y = output_array\n",
    "# Both are a list with the patches and output_arrays for multiple images (the number chosen before)\n",
    "image_patches, output_array = prepareMultipleImages(training_raw_matrices[0:nr_images_training], training_manual1_matrices[0:nr_images_training], \n",
    "                                                     training_mask_matrices[0:nr_images_training], 32, mask_removal = 'patch')\n",
    "test_image_patches, test_output_array = prepareMultipleImages(test_raw_matrices[0:nr_images_test], test_manual1_matrices[0:nr_images_test], \n",
    "                                                     test_mask_matrices[0:nr_images_test], 32, mask_removal = 'patch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Algorithm setup</h4>\n",
    "The following algorithms are to show how the data set is built up. There are patches of 32x 32. These values either correspond to a vene pixel or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_validation_set(image_patches, output_array):\n",
    "    all_train_patches = []\n",
    "    all_train_output = []\n",
    "\n",
    "    for i in range(nr_images_training):\n",
    "        if i <= (nr_images_training-1)/2 :\n",
    "            for j in range(len(image_patches[i])):\n",
    "                all_train_patches.append(image_patches[i][j])\n",
    "                all_train_output.append(output_array[i][j])\n",
    "        else:\n",
    "            valid_patches = image_patches[i]\n",
    "            valid_output = output_array[i]\n",
    "    \n",
    "    return all_train_patches, all_train_output, valid_patches, valid_output\n",
    "\n",
    "def hot_encoding(all_train_output, valid_output):\n",
    "    train_hot_output = np.zeros((len(all_train_output),2),dtype=np.int16)\n",
    "\n",
    "    # Make hot encoding training set\n",
    "    for i in range(len(train_hot_output)):\n",
    "        if all_train_output[i] == 0:\n",
    "            train_hot_output[i,0] = 1\n",
    "        else:\n",
    "            train_hot_output[i,1] = 1      \n",
    "\n",
    "    # Make hot encoding validation set\n",
    "    valid_hot_output = np.zeros((len(valid_output),2),dtype=np.int16)\n",
    "\n",
    "    for i in range(len(valid_hot_output)):\n",
    "        if valid_output[i] == 0:\n",
    "            valid_hot_output[i,0] = 1\n",
    "        else:\n",
    "            valid_hot_output[i,1] = 1\n",
    "    \n",
    "    return train_hot_output, valid_hot_output\n",
    "\n",
    "\n",
    "def test_set(test_image_patches, test_output_array):\n",
    "    all_test_patches = []\n",
    "    all_test_output_array = []\n",
    "    \n",
    "    for i in range(nr_images_test):\n",
    "        for j in range(len(test_image_patches[i])):\n",
    "            all_test_patches.append(test_image_patches[i][j])\n",
    "            all_test_output_array.append(test_output_array[i][j])\n",
    "                \n",
    "    return all_test_patches, all_test_output_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to first make the output array. This is done with hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_train_patches, all_train_output, valid_patches, valid_output = train_and_validation_set(image_patches, output_array)\n",
    "train_hot_output, valid_hot_output = hot_encoding(all_train_output, valid_output)\n",
    "\n",
    "all_test_patches, all_test_output_array = test_set(test_image_patches, test_output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the LeNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildLeNet(X1):\n",
    "    #rectify, softmax, sigmoid\n",
    "    inputlayer = lasagne.layers.InputLayer(shape=(None, 1, 32, 32),input_var=X1)    \n",
    "    print inputlayer.output_shape\n",
    "    \n",
    "    layer1 = lasagne.layers.Conv2DLayer(inputlayer, num_filters=6, filter_size=(5,5), nonlinearity=lasagne.nonlinearities.rectify, W=lasagne.init.GlorotUniform())\n",
    "    print layer1.output_shape \n",
    "    \n",
    "    layer2 = lasagne.layers.MaxPool2DLayer(layer1, pool_size=(2, 2))\n",
    "    print layer2.output_shape \n",
    "    \n",
    "    layer3 = lasagne.layers.Conv2DLayer(layer2, num_filters=16, filter_size=(5,5), nonlinearity=lasagne.nonlinearities.rectify, W=lasagne.init.GlorotUniform())\n",
    "    print layer3.output_shape \n",
    "    \n",
    "    layer4 = lasagne.layers.MaxPool2DLayer(layer3, pool_size=(2, 2))\n",
    "    print layer4.output_shape \n",
    "    \n",
    "    layer4 = lasagne.layers.flatten(layer4)\n",
    "    print layer4.output_shape \n",
    "    \n",
    "    layer5 = lasagne.layers.DenseLayer(layer4,num_units=120,nonlinearity=lasagne.nonlinearities.rectify)    \n",
    "    print layer5.output_shape \n",
    "    \n",
    "    layer6 = lasagne.layers.DenseLayer(layer5,num_units=84,nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    print layer6.output_shape \n",
    "    \n",
    "    outputlayer = lasagne.layers.DenseLayer(layer6,num_units=2,nonlinearity=lasagne.nonlinearities.softmax)     \n",
    "    print outputlayer.output_shape \n",
    "    \n",
    "    return layer1, layer2, layer3, layer4, layer5, layer6, outputlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 32, 32)\n",
      "(None, 6, 28, 28)\n",
      "(None, 6, 14, 14)\n",
      "(None, 16, 10, 10)\n",
      "(None, 16, 5, 5)\n",
      "(None, 400)\n",
      "(None, 120)\n",
      "(None, 84)\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "X = theano.tensor.tensor4()\n",
    "Y = theano.tensor.matrix()\n",
    "layer1, layer2, layer3, layer4, layer5, layer6, outputlayer = buildLeNet(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions for training, validation and testing purposes for the previously made LeNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atte\\Anaconda2\\lib\\site-packages\\lasagne\\layers\\conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.\n",
      "  border_mode=border_mode)\n"
     ]
    }
   ],
   "source": [
    "outputtrain = lasagne.layers.get_output(outputlayer) #function that gets the output from the network defined before.\n",
    "trainloss = lasagne.objectives.categorical_crossentropy(outputtrain, Y).mean() #function that computes the mean crossentropy between the output and the real labels.\n",
    "params = lasagne.layers.get_all_params(outputlayer, trainable=True) #function that gets all the parameters (weights) in the network.\n",
    "updates = lasagne.updates.momentum(trainloss, params, learning_rate=0.001) #function that performs an update of the weights based on the loss.\n",
    "train = theano.function(inputs=[X, Y], outputs=trainloss, updates=updates, allow_input_downcast=True) #function that does all the above based on training samples X and real labels Y.\n",
    "\n",
    "validate = theano.function(inputs=[X, Y], outputs=trainloss, allow_input_downcast=True) #function that computes the loss without performing an update\n",
    "\n",
    "outputtest = lasagne.layers.get_output(outputlayer, deterministic=True) #function that gets the output from the network defined before.\n",
    "test = theano.function(inputs=[X], outputs=outputtest, allow_input_downcast=True) #function that gets the output based on input X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training_the_network(all_train_output, valid_output, all_train_patches, valid_patches, minibatches = 250, minibatchsize = 100):\n",
    "\n",
    "    trainingsamples = np.arange(len(all_train_output)) #numbers from 0 until the number of samples\n",
    "    validsamples = np.arange(len(valid_output))\n",
    "\n",
    "    losslist = []\n",
    "    validlosslist = []\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    for i in xrange(minibatches):\n",
    "        print(\"Currently at batch %d\" % i)\n",
    "\n",
    "        # Random train sample information. IMPORTANT: Use the hot encoded labels (that's the way the algorithm works)\n",
    "        random_train_patches, random_train_output = sampleBatches(all_train_patches, all_train_output, \n",
    "                                                                  batch_size = minibatchsize, distribution = 0.5)\n",
    "\n",
    "        # Random validation sample information IMPORTANT: Use the hot encoded labels (that's the way the algorithm works)\n",
    "        random_valid_patches, random_valid_output = sampleBatches(valid_patches, valid_output, \n",
    "                                                                  batch_size = minibatchsize, distribution = 0.5)\n",
    "\n",
    "        new_train_loss = train(random_train_patches, random_train_output)\n",
    "        losslist.append(new_train_loss)\n",
    "\n",
    "        new_valid_loss = validate(random_valid_patches, random_valid_output)\n",
    "        validlosslist.append(new_valid_loss)\n",
    "        #select random training en validation samples and perform training and validation steps here.\n",
    "\n",
    "    t1 = time.time()\n",
    "    print 'Training time: {} seconds'.format(t1-t0)\n",
    "    \n",
    "    return losslist, validlosslist\n",
    "\n",
    "\n",
    "# Creates bathces of vessel and non vessel images of a certain distribution\n",
    "def sampleBatches(input_patches, output_array, batch_size = 100, distribution = 0.5):\n",
    "    if len(input_patches) != len(output_array):\n",
    "        raise Exception(\"Length of input and output is different\")\n",
    "    \n",
    "    if distribution < 0 or distribution > 1:\n",
    "        raise Exception(\"Impossible distribution\")\n",
    "        \n",
    "    non_vessel_patches = []\n",
    "    vessel_patches = []\n",
    "    \n",
    "    #First create two lists. One with vessel patches and one without\n",
    "    for i in range(len(input_patches)):\n",
    "        if output_array[i] == 0:\n",
    "            non_vessel_patches.append(input_patches[i])\n",
    "            \n",
    "        else:\n",
    "            vessel_patches.append(input_patches[i])\n",
    "            \n",
    "    # Choose non vessel patches for in the batch\n",
    "    samples_non_vessel = np.arange(len(non_vessel_patches)) #numbers from 0 until the number of samples\n",
    "    random_non_vessel_samples = random.sample(samples_non_vessel, int(batch_size * distribution))\n",
    "    non_vessel_output = int(batch_size * distribution) * [[1, 0]] #all these were non-vessel\n",
    "    non_vessel_patches = np.asarray(non_vessel_patches)[random_non_vessel_samples]\n",
    "    \n",
    "    # Choose vessel patches for in the batch\n",
    "    samples_vessel = np.arange(len(vessel_patches)) #numbers from 0 until the number of samples\n",
    "    random_vessel_samples = random.sample(samples_vessel, int(batch_size * (1 - distribution)))\n",
    "    vessel_output = int(batch_size * (1 - distribution)) * [[0, 1]]\n",
    "    vessel_patches = np.asarray(vessel_patches)[random_vessel_samples]\n",
    "             \n",
    "    # Combine the batches    \n",
    "    batch_patches = np.append(non_vessel_patches, vessel_patches, axis = 0)\n",
    "    batch_output = np.append(non_vessel_output, vessel_output, axis = 0)\n",
    "                                          \n",
    "    return batch_patches, batch_output\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at batch 0\n",
      "Currently at batch 1\n",
      "Currently at batch 2\n",
      "Currently at batch 3\n",
      "Currently at batch 4\n",
      "Currently at batch 5\n",
      "Currently at batch 6\n",
      "Currently at batch 7\n",
      "Currently at batch 8\n",
      "Currently at batch 9\n",
      "Currently at batch 10\n",
      "Currently at batch 11\n",
      "Currently at batch 12\n",
      "Currently at batch 13\n",
      "Currently at batch 14\n",
      "Currently at batch 15\n",
      "Currently at batch 16\n",
      "Currently at batch 17\n",
      "Currently at batch 18\n",
      "Currently at batch 19\n",
      "Currently at batch 20\n",
      "Currently at batch 21\n",
      "Currently at batch 22\n",
      "Currently at batch 23\n",
      "Currently at batch 24\n",
      "Currently at batch 25\n",
      "Currently at batch 26\n",
      "Currently at batch 27\n",
      "Currently at batch 28\n",
      "Currently at batch 29\n",
      "Training time: 152.774999857 seconds\n"
     ]
    }
   ],
   "source": [
    "losslist, validlosslist = training_the_network(all_train_output, valid_output, all_train_patches, valid_patches, minibatches = 30, minibatchsize = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhAK6iEhEKKCLiETE/wdSnk55aUtdbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf5e1128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192286L, 1L, 32L, 32L)\n",
      "[array(0.6933253615039198), array(0.6934071263766968), array(0.6935119855762508), array(0.6936324671990244), array(0.6937619222705541), array(0.6939024226835561), array(0.6940409562917842), array(0.6941863318899594), array(0.694341197938478)]\n"
     ]
    }
   ],
   "source": [
    "#plt.figure()\n",
    "#plt.plot(losslist)\n",
    "#plt.plot(validlosslist)\n",
    "#plt.legend(['Training loss','Validation loss'])\n",
    "#plt.show()\n",
    "print np.shape(all_test_patches)\n",
    "print losslist[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]\n",
      " [ 0.52714401  0.47285599]]\n",
      "Testing time: 0.450999975204 seconds\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "testing = test(all_test_patches[100:600])\n",
    "print(testing)\n",
    "test_set_predictions = np.argmax(testing, axis = 1)\n",
    "t1 = time.time()\n",
    "print 'Testing time: {} seconds'.format(t1-t0)\n",
    "\n",
    "print test_set_predictions\n",
    "print sum(test_set_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57621L, 6L, 28L, 28L)\n"
     ]
    }
   ],
   "source": [
    "#outputlayer1 = lasagne.layers.get_output(layer1) \n",
    "#outputfeatures = theano.function(inputs=[X], outputs=outputlayer1, allow_input_downcast=True) \n",
    "\n",
    "#features = outputfeatures(all_test_patches[1000:58621])\n",
    "#print np.shape(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57621L, 6L, 28L, 28L)\n"
     ]
    }
   ],
   "source": [
    "#print features.shape\n",
    "#for i in xrange(6):\n",
    "#    plt.figure()\n",
    "#    plt.imshow(features[1,i],cmap='gray_r',interpolation='none')\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'numpytest.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-43f18661d9cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'losslist.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosslist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'validlosslist.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidlosslist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloadaa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'numpytest.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mloadaa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Atte\\Anaconda2\\lib\\site-packages\\numpy\\lib\\npyio.pyc\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbz2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                 \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'U'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'numpytest.txt'"
     ]
    }
   ],
   "source": [
    "#np.savetxt('test_set_predictions.txt', test_set_predictions)\n",
    "#np.savetxt('losslist.txt', losslist)\n",
    "#np.savetxt('validlosslist.txt', validlosslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def save_weights(filename,network):\n",
    "    with open(filename, 'wb') as f:\n",
    "        cPickle.dump(lasagne.layers.get_all_param_values(network), f)\n",
    "        cPickle.dump(test_set_predictions, f)\n",
    "        cPickle.dump(losslist, f)\n",
    "        cPickle.dump(validlosslist, f)\n",
    "        \n",
    "def load_weights(filename, network):\n",
    "    with open(filename, 'rb') as f:\n",
    "        lasagne.layers.set_all_param_values(network, cPickle.load(f))\n",
    "        \n",
    "filename = '/home/8dm20_3/Project CSMIA/Project1_weights.pkl' #C:/Users/Atte/Desktop/Capita selecta/8DM20-CSMIA-group-3/Project/Project1_weights.pkl'\n",
    "network = outputlayer\n",
    "save_weights(filename, network) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
