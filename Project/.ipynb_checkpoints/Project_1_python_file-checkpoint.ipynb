{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep learning project 8DM20 CSMIA</h1>\n",
    "\n",
    "<h4>Group members:</h4>\n",
    "O. Akdag - 0842508 <br>\n",
    "T.P.A. Beishuizen - 0791613 <br>\n",
    "A.S.A. Eskelinen - 1224333 <br>\n",
    "J.H.A. Migchielsen - 0495058 <br>\n",
    "L. van den Wildenberg - 0844697 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "C:\\Users\\s119104\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "# Import all used packages (unused packages are commented out so far)\n",
    "import os\n",
    "from PIL import Image as PIL_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from sklearn.feature_extraction import image as sklearn_image\n",
    "#matplotlib inline\n",
    "import theano\n",
    "import lasagne\n",
    "import time\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before every thing can be done, at first the data images have to be read and be made in useable data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function that loads the data\n",
    "def loadData(data_set = 'test', image = '1st_manual'):\n",
    "    \n",
    "    # Check for the correct input\n",
    "    if data_set != 'test' and data_set != 'training':\n",
    "        raise Exception('Not the right data_set file')\n",
    "    if image != '1st_manual' and image != '2nd_manual' and image != 'images' and image != 'mask':\n",
    "        raise Exception('Not the right image file')\n",
    "    if data_set == 'training' and image == '2nd_manual':\n",
    "        raise Exception('File not available')\n",
    "    \n",
    "    # Project and image path\n",
    "    project_path = os.getcwd()\n",
    "    images_path = project_path +  '/8DM20_image_dataset/' + data_set + '/' + image + '/'\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    #Open image for image (20 in total for each of them)\n",
    "    for i in range(1, 21):\n",
    "        \n",
    "        # Find correct image number\n",
    "        image_nr = str(i)\n",
    "        if data_set == 'training':\n",
    "            image_nr = str(20 + i)\n",
    "        elif len(image_nr) == 1:\n",
    "            image_nr = '0' + image_nr\n",
    "            \n",
    "        # Specify path for this image\n",
    "        if image == '1st_manual':\n",
    "            image_path = images_path + image_nr + '_manual1.gif'\n",
    "        elif image == '2nd_manual':\n",
    "            image_path = images_path + image_nr + '_manual2.gif'\n",
    "        elif image == 'images':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '.tif'\n",
    "        elif image == 'mask':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '_mask.gif'\n",
    "        \n",
    "        # Open and append the image to the image list\n",
    "        images.append(PIL_image.open(image_path))\n",
    "        \n",
    "    return images\n",
    "\n",
    "#The function that converts the channels in the images from RGB to gray\n",
    "#and makes matrices from the images\n",
    "def convertImageToMatrix(images):\n",
    "    \n",
    "    image_matrices = []\n",
    "    \n",
    "    for image in images:\n",
    "        image_matrix = np.asarray(image.convert('L'))\n",
    "        image_matrices.append(image_matrix)\n",
    "        \n",
    "    return image_matrices\n",
    "\n",
    "#The function that prepares the image matrices to the data used for machine learning\n",
    "def prepareMachineLearningData(image_matrix, output_matrix, mask_matrix, kernel_size = 25):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrix, np.ndarray) and \n",
    "            isinstance(output_matrix, np.ndarray) and \n",
    "            isinstance(mask_matrix, np.ndarray)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if not (image_matrix.shape == output_matrix.shape == mask_matrix.shape):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    #if np.unique(output_matrix).shape[0] != 3:\n",
    "    #   raise Exception(\"The output matrix does not consist of only 3 values\")\n",
    "    \n",
    "    if np.unique(mask_matrix).shape[0] != 2:\n",
    "        raise Exception(\"The mask matrix does not consist of only 2 values\")\n",
    "    \n",
    "    #Creates a matrix with all possible patches\n",
    "    all_image_patches = sklearn_image.extract_patches_2d(image_matrix,(kernel_size,kernel_size))\n",
    "    all_image_patches = np.expand_dims(all_image_patches, axis=1)\n",
    "    \n",
    "    if kernel_size % 2 != 0:\n",
    "         # Creates an array with all output\n",
    "        matrix_reduction = (kernel_size - 1) / 2\n",
    "        reduced_output_matrix = output_matrix[matrix_reduction : - matrix_reduction, matrix_reduction : - matrix_reduction]\n",
    "        complete_output_array = reduced_output_matrix.reshape(-1)\n",
    "\n",
    "        # Creates an array with all mask locations\n",
    "        reduced_mask_matrix = mask_matrix[matrix_reduction : - matrix_reduction, matrix_reduction : - matrix_reduction]\n",
    "        mask_array = reduced_mask_matrix.reshape(-1)\n",
    "    \n",
    "    else:\n",
    "        # Creates an array with all output\n",
    "        matrix_reduction = (kernel_size) / 2\n",
    "        reduced_output_matrix = output_matrix[matrix_reduction + 1 : - matrix_reduction, matrix_reduction + 1 : - matrix_reduction]\n",
    "        complete_output_array = reduced_output_matrix.reshape(-1)\n",
    "\n",
    "        # Creates an array with all mask locations\n",
    "        reduced_mask_matrix = mask_matrix[matrix_reduction + 1 : - matrix_reduction, matrix_reduction + 1 : - matrix_reduction]\n",
    "        mask_array = reduced_mask_matrix.reshape(-1) \n",
    "    \n",
    "    image_patches = []\n",
    "    output_array = []\n",
    "    \n",
    "    # Reduces the number of patches and output to only the mask values\n",
    "    for i in range(len(mask_array)):\n",
    "        if mask_array[i] != 0:\n",
    "            image_patches.append(all_image_patches[i,:,:])\n",
    "            output_array.append(complete_output_array[i])\n",
    "\n",
    "    # Return the image patches and the output array\n",
    "    return image_patches, output_array\n",
    "\n",
    "# Prepare multiple images at once\n",
    "def prepareMultipleImages(image_matrices, output_matrices, mask_matrices, kernel_size = 25):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrices, list) and \n",
    "            isinstance(output_matrices, list) and \n",
    "            isinstance(mask_matrices, list)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if not (len(image_matrices) == len(output_matrices) == len(mask_matrices)):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    image_patches = [] \n",
    "    output_arrays = []\n",
    "    \n",
    "    # Finds the output data per image\n",
    "    for i in range(len(image_matrices)):\n",
    "        new_image_patches, new_output_array = prepareMachineLearningData(image_matrices[i], output_matrices[i], \n",
    "                                                                         mask_matrices[i], kernel_size = kernel_size)\n",
    "        image_patches.append(new_image_patches)\n",
    "        output_arrays.append(new_output_array)\n",
    "        \n",
    "        #Print progress for showing time consumption\n",
    "        print\"Progress: {} %\".format(100*(i+1)/len(image_matrices)),\n",
    "              \n",
    "    return image_patches, output_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are loaded and immediately made into matrices for further computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All test image lists\n",
    "test_manual1_images = loadData('test', '1st_manual')\n",
    "test_manual2_images = loadData('test', '2nd_manual')\n",
    "test_raw_images = loadData('test', 'images')\n",
    "test_mask_images = loadData('test', 'mask')\n",
    "\n",
    "# Making matrices of the test images to work with\n",
    "test_manual1_matrices = convertImageToMatrix(test_manual1_images)\n",
    "test_manual2_matrices = convertImageToMatrix(test_manual2_images)\n",
    "test_raw_matrices = convertImageToMatrix(test_raw_images)\n",
    "test_mask_matrices = convertImageToMatrix(test_mask_images)\n",
    "\n",
    "# All training image lists\n",
    "training_manual1_images = loadData('training', '1st_manual')\n",
    "training_raw_images = loadData('training', 'images')\n",
    "training_mask_images = loadData('training', 'mask')\n",
    "\n",
    "# Making matrices of the training images to work with\n",
    "training_manual1_matrices = convertImageToMatrix(training_manual1_images)\n",
    "training_raw_matrices = convertImageToMatrix(training_raw_images)\n",
    "training_mask_matrices = convertImageToMatrix(training_mask_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrices are then used for further preprocessing to retrieve the suitable data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 50 % Progress: 100 %\n"
     ]
    }
   ],
   "source": [
    "#Choose the number of images\n",
    "nr_images = 2\n",
    "\n",
    "# Prepares the data for machine learning: X = image_patches, y = output_array\n",
    "# Both are a list with the patches and output_arrays for multiple images (the number chosen before)\n",
    "image_patches, output_array = prepareMultipleImages(test_raw_matrices[0:nr_images], test_manual1_matrices[0:nr_images], \n",
    "                                                     test_mask_matrices[0:nr_images], 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is just to show how the data set is built up. There are patches of 25x 25. These values either correspond to a vene pixel or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xaebdcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be vene pixel? 0 (255 is yes, 0 is no)\n"
     ]
    }
   ],
   "source": [
    "image_number = 1\n",
    "pixel = 35620 #35645\n",
    "\n",
    "\n",
    "np.asarray(image_patches[1]).shape\n",
    "\n",
    "plt.matshow(image_patches[image_number][pixel][0])\n",
    "plt.show()\n",
    "\n",
    "print(\"Should be vene pixel? \" + str(output_array[image_number][pixel]) + \" (255 is yes, 0 is no)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
