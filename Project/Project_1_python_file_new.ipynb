{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep learning project 8DM20 CSMIA</h1>\n",
    "\n",
    "<h4>Group members:</h4>\n",
    "O. Akdag - 0842508 <br>\n",
    "T.P.A. Beishuizen - 0791613 <br>\n",
    "A.S.A. Eskelinen - 1224333 <br>\n",
    "J.H.A. Migchielsen - 0495058 <br>\n",
    "L. van den Wildenberg - 0844697 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s119104\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "# Import all used packages (unused packages are commented out so far)\n",
    "import os\n",
    "from PIL import Image as PIL_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from sklearn.feature_extraction import image as sklearn_image\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "#matplotlib inline\n",
    "import theano\n",
    "import lasagne\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import cPickle\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Preprocessing</h4>\n",
    "\n",
    "Before every thing can be done, at first the data images have to be read and be made in useable data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function that loads the data\n",
    "def loadData(data_set = 'test', image = '1st_manual'):\n",
    "    \n",
    "    # Check for the correct input\n",
    "    if data_set != 'test' and data_set != 'training':\n",
    "        raise Exception('Not the right data_set file')\n",
    "    if image != '1st_manual' and image != '2nd_manual' and image != 'images' and image != 'mask':\n",
    "        raise Exception('Not the right image file')\n",
    "    if data_set == 'training' and image == '2nd_manual':\n",
    "        raise Exception('File not available')\n",
    "    \n",
    "    # Project and image path\n",
    "    project_path = os.getcwd()\n",
    "    images_path = project_path +  '/8DM20_image_dataset/' + data_set + '/' + image + '/'\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    #Open image for image (20 in total for each of them)\n",
    "    for i in range(1, 21):\n",
    "        \n",
    "        # Find correct image number\n",
    "        image_nr = str(i)\n",
    "        if data_set == 'training':\n",
    "            image_nr = str(20 + i)\n",
    "        elif len(image_nr) == 1:\n",
    "            image_nr = '0' + image_nr\n",
    "            \n",
    "        # Specify path for this image\n",
    "        if image == '1st_manual':\n",
    "            image_path = images_path + image_nr + '_manual1.gif'\n",
    "        elif image == '2nd_manual':\n",
    "            image_path = images_path + image_nr + '_manual2.gif'\n",
    "        elif image == 'images':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '.tif'\n",
    "        elif image == 'mask':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '_mask.gif'\n",
    "        \n",
    "        # Open and append the image to the image list\n",
    "        images.append(PIL_image.open(image_path))\n",
    "        \n",
    "    return images\n",
    "\n",
    "#The function that converts the channels in the images from RGB to gray\n",
    "#and makes matrices from the images\n",
    "def convertImageToMatrix(images):\n",
    "    \n",
    "    image_matrices = []\n",
    "    \n",
    "    for image in images:\n",
    "        image_matrix = np.asarray(image.convert('RGB'))\n",
    "        green_image_matrix = image_matrix[:,:,1]\n",
    "        image_matrices.append(green_image_matrix)\n",
    "        \n",
    "    return image_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are loaded and immediately made into matrices for further computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All test image lists\n",
    "test_manual1_images = loadData('test', '1st_manual')\n",
    "test_manual2_images = loadData('test', '2nd_manual')\n",
    "test_raw_images = loadData('test', 'images')\n",
    "test_mask_images = loadData('test', 'mask')\n",
    "\n",
    "# Making matrices of the test images to work with\n",
    "test_manual1_matrices = convertImageToMatrix(test_manual1_images)\n",
    "test_manual2_matrices = convertImageToMatrix(test_manual2_images)\n",
    "test_raw_matrices = convertImageToMatrix(test_raw_images)\n",
    "test_mask_matrices = convertImageToMatrix(test_mask_images)\n",
    "\n",
    "# All training image lists\n",
    "training_manual1_images = loadData('training', '1st_manual')\n",
    "training_raw_images = loadData('training', 'images')\n",
    "training_mask_images = loadData('training', 'mask')\n",
    "\n",
    "# Making matrices of the training images to work with\n",
    "training_manual1_matrices = convertImageToMatrix(training_manual1_images)\n",
    "training_raw_matrices = convertImageToMatrix(training_raw_images)\n",
    "training_mask_matrices = convertImageToMatrix(training_mask_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrices are then used for further preprocessing to retrieve the suitable data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19L, 616L, 597L)\n",
      "(1L, 616L, 597L)\n",
      "(19L, 616L, 597L)\n",
      "(1L, 616L, 597L)\n",
      "(19L, 616L, 597L)\n",
      "(1L, 616L, 597L)\n"
     ]
    }
   ],
   "source": [
    "kernel_size = 32 \n",
    "halfsize = kernel_size/ 2\n",
    "\n",
    "#Add side pads to the image to convert them better\n",
    "train_images = np.pad(training_raw_matrices[0:19],((0,0),(halfsize,halfsize),(halfsize,halfsize)),'constant', constant_values=0)\n",
    "valid_images = np.pad(training_raw_matrices[19:20],((0,0),(halfsize,halfsize),(halfsize,halfsize)),'constant', constant_values=0)\n",
    "train_masks = np.pad(training_mask_matrices[0:19],((0,0),(halfsize,halfsize),(halfsize,halfsize)),'constant', constant_values=0)\n",
    "valid_masks = np.pad(training_mask_matrices[19:20],((0,0),(halfsize,halfsize),(halfsize,halfsize)),'constant', constant_values=0)\n",
    "train_segmentations = np.pad(training_manual1_matrices[0:19],((0,0),(halfsize,halfsize),(halfsize,halfsize)),'constant', constant_values=0)\n",
    "valid_segmentations = np.pad(training_manual1_matrices[19:20],((0,0),(halfsize,halfsize),(halfsize,halfsize)),'constant', constant_values=0)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(valid_images.shape)\n",
    "print(train_masks.shape)\n",
    "print(valid_masks.shape)\n",
    "print(train_segmentations.shape)\n",
    "print(valid_segmentations.shape)\n",
    "\n",
    "train_positivesamples = np.nonzero(train_segmentations*train_masks)\n",
    "train_negativesamples = np.nonzero(train_masks-train_segmentations)  \n",
    "\n",
    "valid_positivesamples = np.nonzero(valid_segmentations*valid_masks)\n",
    "valid_negativesamples = np.nonzero(valid_masks-valid_segmentations)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Algorithm setup</h4>\n",
    "Build the LeNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildLeNet(X1):\n",
    "    inputlayer = lasagne.layers.InputLayer(shape=(None, 1, 32, 32),input_var=X1)    \n",
    "    print inputlayer.output_shape\n",
    "    \n",
    "    layer1 = lasagne.layers.Conv2DLayer(inputlayer, num_filters=6, filter_size=(5,5), nonlinearity=lasagne.nonlinearities.rectify, W=lasagne.init.GlorotUniform())\n",
    "    print layer1.output_shape \n",
    "    \n",
    "    layer2 = lasagne.layers.MaxPool2DLayer(layer1, pool_size=(2, 2))\n",
    "    print layer2.output_shape \n",
    "    \n",
    "    layer3 = lasagne.layers.Conv2DLayer(layer2, num_filters=16, filter_size=(5,5), nonlinearity=lasagne.nonlinearities.rectify, W=lasagne.init.GlorotUniform())\n",
    "    print layer3.output_shape \n",
    "    \n",
    "    layer4 = lasagne.layers.MaxPool2DLayer(layer3, pool_size=(2, 2))\n",
    "    print layer4.output_shape \n",
    "    \n",
    "    layer4 = lasagne.layers.flatten(layer4)\n",
    "    print layer4.output_shape \n",
    "    \n",
    "    layer5 = lasagne.layers.DenseLayer(layer4,num_units=120,nonlinearity=lasagne.nonlinearities.rectify)    \n",
    "    print layer5.output_shape \n",
    "    \n",
    "    layer6 = lasagne.layers.DenseLayer(layer5,num_units=84,nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    print layer6.output_shape \n",
    "    \n",
    "    outputlayer = lasagne.layers.DenseLayer(layer6,num_units=2,nonlinearity=lasagne.nonlinearities.softmax)     \n",
    "    print outputlayer.output_shape \n",
    "    \n",
    "    return layer1, layer2, layer3, layer4, layer5, layer6, outputlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 32, 32)\n",
      "(None, 6, 28, 28)\n",
      "(None, 6, 14, 14)\n",
      "(None, 16, 10, 10)\n",
      "(None, 16, 5, 5)\n",
      "(None, 400)\n",
      "(None, 120)\n",
      "(None, 84)\n",
      "(None, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s119104\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\lasagne\\layers\\conv.py:489: UserWarning: The `image_shape` keyword argument to `tensor.nnet.conv2d` is deprecated, it has been renamed to `input_shape`.\n",
      "  border_mode=border_mode)\n"
     ]
    }
   ],
   "source": [
    "X = theano.tensor.tensor4()\n",
    "Y = theano.tensor.matrix()\n",
    "layer1, layer2, layer3, layer4, layer5, layer6, outputlayer = buildLeNet(X)\n",
    "\n",
    "outputtrain = lasagne.layers.get_output(outputlayer) \n",
    "trainloss = lasagne.objectives.categorical_crossentropy(outputtrain, Y).mean() \n",
    "params = lasagne.layers.get_all_params(outputlayer, trainable=True) \n",
    "updates = lasagne.updates.adam(trainloss, params, learning_rate=0.001) \n",
    "train = theano.function(inputs=[X, Y], outputs=trainloss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "validate = theano.function(inputs=[X, Y], outputs=trainloss, allow_input_downcast=True)\n",
    "\n",
    "outputtest = lasagne.layers.get_output(outputlayer, deterministic=True) \n",
    "test = theano.function(inputs=[X], outputs=outputtest, allow_input_downcast=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions for training, validation and testing purposes for the previously made LeNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make2Dpatches(samples, batch, images, patchsize, label):\n",
    "    \n",
    "    halfsize = int(patchsize/2)\n",
    "    \n",
    "    X = np.empty([len(batch),1,patchsize,patchsize],dtype=np.float32)\n",
    "        \n",
    "    Y = np.zeros((len(batch),2),dtype=np.int16) \n",
    "        \n",
    "    for i in xrange(len(batch)):\n",
    "        \n",
    "        patch = images[samples[0][batch[i]],(samples[1][batch[i]]-halfsize):(samples[1][batch[i]]+halfsize),(samples[2][batch[i]]-halfsize):(samples[2][batch[i]]+halfsize)]\n",
    "       \n",
    "        X[i,0] = patch        \n",
    "        Y[i,label] = 1 \n",
    "        \n",
    "    return X, Y\n",
    "\n",
    "def save_weights(filename,network):\n",
    "    with open(filename, 'wb') as f:\n",
    "        cPickle.dump(lasagne.layers.get_all_param_values(network), f)\n",
    "        cPickle.dump(losslist, f)\n",
    "        cPickle.dump(validlosslist, f)\n",
    "        cPickle.dump(test_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at batch 0, has loss of 1.66 and validloss of 0.96 \n",
      "Currently at batch 1, has loss of 1.18 and validloss of 0.71 \n",
      "Currently at batch 2, has loss of 0.78 and validloss of 0.76 \n",
      "Currently at batch 3, has loss of 0.86 and validloss of 0.93 \n",
      "Currently at batch 4, has loss of 1.16 and validloss of 1.05 \n",
      "Currently at batch 5, has loss of 1.23 and validloss of 0.92 \n",
      "Currently at batch 6, has loss of 1.02 and validloss of 0.77 \n",
      "Currently at batch 7, has loss of 0.91 and validloss of 0.67 \n",
      "Currently at batch 8, has loss of 0.74 and validloss of 0.65 \n",
      "Currently at batch 9, has loss of 0.71 and validloss of 0.70 \n",
      "Currently at batch 10, has loss of 0.81 and validloss of 0.73 \n",
      "Currently at batch 11, has loss of 0.89 and validloss of 0.81 \n",
      "Currently at batch 12, has loss of 0.84 and validloss of 0.70 \n",
      "Currently at batch 13, has loss of 0.87 and validloss of 0.67 \n",
      "Currently at batch 14, has loss of 0.74 and validloss of 0.67 \n",
      "Currently at batch 15, has loss of 0.69 and validloss of 0.67 \n",
      "Currently at batch 16, has loss of 0.61 and validloss of 0.57 \n",
      "Currently at batch 17, has loss of 0.63 and validloss of 0.60 \n",
      "Currently at batch 18, has loss of 0.75 and validloss of 0.67 \n",
      "Currently at batch 19, has loss of 0.68 and validloss of 0.66 \n",
      "Currently at batch 20, has loss of 0.71 and validloss of 0.64 \n",
      "Currently at batch 21, has loss of 0.74 and validloss of 0.66 \n",
      "Currently at batch 22, has loss of 0.66 and validloss of 0.64 \n",
      "Currently at batch 23, has loss of 0.61 and validloss of 0.60 \n",
      "Currently at batch 24, has loss of 0.69 and validloss of 0.60 \n",
      "Currently at batch 25, has loss of 0.68 and validloss of 0.61 \n",
      "Currently at batch 26, has loss of 0.62 and validloss of 0.62 \n",
      "Currently at batch 27, has loss of 0.66 and validloss of 0.61 \n",
      "Currently at batch 28, has loss of 0.63 and validloss of 0.58 \n",
      "Currently at batch 29, has loss of 0.61 and validloss of 0.65 \n",
      "Currently at batch 30, has loss of 0.66 and validloss of 0.64 \n",
      "Currently at batch 31, has loss of 0.56 and validloss of 0.57 \n",
      "Currently at batch 32, has loss of 0.64 and validloss of 0.59 \n",
      "Currently at batch 33, has loss of 0.62 and validloss of 0.57 \n",
      "Currently at batch 34, has loss of 0.68 and validloss of 0.61 \n",
      "Currently at batch 35, has loss of 0.56 and validloss of 0.59 \n",
      "Currently at batch 36, has loss of 0.62 and validloss of 0.54 \n",
      "Currently at batch 37, has loss of 0.56 and validloss of 0.60 \n",
      "Currently at batch 38, has loss of 0.59 and validloss of 0.59 \n",
      "Currently at batch 39, has loss of 0.57 and validloss of 0.56 \n"
     ]
    }
   ],
   "source": [
    "minibatches = 1000\n",
    "minibatchsize = 200\n",
    "\n",
    "losslist = []\n",
    "validlosslist = []\n",
    "        \n",
    "for i in xrange(minibatches):\n",
    "    train_posbatch = random.sample(range(len(train_positivesamples[0])),minibatchsize/2)\n",
    "    train_negbatch = random.sample(range(len(train_negativesamples[0])),minibatchsize/2)\n",
    "             \n",
    "    train_Xpos, train_Ypos = make2Dpatches(train_positivesamples,train_posbatch,train_images,32,1)\n",
    "    train_Xneg, train_Yneg = make2Dpatches(train_negativesamples,train_negbatch,train_images,32,0)\n",
    "          \n",
    "    Xtrain = np.vstack((train_Xpos,train_Xneg))\n",
    "    Ytrain = np.vstack((train_Ypos,train_Yneg))\n",
    "    \n",
    "    valid_posbatch = random.sample(range(len(valid_positivesamples[0])),minibatchsize/2)\n",
    "    valid_negbatch = random.sample(range(len(valid_negativesamples[0])),minibatchsize/2)\n",
    "             \n",
    "    valid_Xpos, valid_Ypos = make2Dpatches(valid_positivesamples,valid_posbatch,valid_images,32,1)\n",
    "    valid_Xneg, valid_Yneg = make2Dpatches(valid_negativesamples,valid_negbatch,valid_images,32,0)\n",
    "          \n",
    "    Xvalid = np.vstack((valid_Xpos,valid_Xneg))\n",
    "    Yvalid = np.vstack((valid_Ypos,valid_Yneg))\n",
    "    \n",
    "    loss = train(Xtrain,Ytrain)\n",
    "    losslist.append(loss)\n",
    "    \n",
    "    validloss = validate(Xvalid, Yvalid)\n",
    "    validlosslist.append(validloss)\n",
    "    print(\"Currently at batch %d, has loss of %0.2f and validloss of %0.2f \" % (i, loss, validloss))\n",
    "                \n",
    "        \n",
    "#plt.close('all')\n",
    "#plt.figure()\n",
    "#plt.plot(losslist)    \n",
    "\n",
    "project_path = os.getcwd()\n",
    "filename = project_path + '/Project1_weights.pkl'\n",
    "save_weights(filename, outputlayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Testing algorithm</h4>\n",
    "Test the algorithm with putting in an image_patch and checking if the result is correct."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
