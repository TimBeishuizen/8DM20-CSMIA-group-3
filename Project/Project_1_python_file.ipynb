{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep learning project 8DM20 CSMIA</h1>\n",
    "\n",
    "<h4>Group members:</h4>\n",
    "O. Akdag - 0842508 <br>\n",
    "T.P.A. Beishuizen - 0791613 <br>\n",
    "A.S.A. Eskelinen - 1224333 <br>\n",
    "J.H.A. Migchielsen - 0495058 <br>\n",
    "L. van den Wildenberg - 0844697 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s119104\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "# Import all used packages (unused packages are commented out so far)\n",
    "import os\n",
    "from PIL import Image as PIL_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from sklearn.feature_extraction import image as sklearn_image\n",
    "#matplotlib inline\n",
    "import theano\n",
    "import lasagne\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Preprocessing</h4>\n",
    "\n",
    "Before every thing can be done, at first the data images have to be read and be made in useable data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function that loads the data\n",
    "def loadData(data_set = 'test', image = '1st_manual'):\n",
    "    \n",
    "    # Check for the correct input\n",
    "    if data_set != 'test' and data_set != 'training':\n",
    "        raise Exception('Not the right data_set file')\n",
    "    if image != '1st_manual' and image != '2nd_manual' and image != 'images' and image != 'mask':\n",
    "        raise Exception('Not the right image file')\n",
    "    if data_set == 'training' and image == '2nd_manual':\n",
    "        raise Exception('File not available')\n",
    "    \n",
    "    # Project and image path\n",
    "    project_path = os.getcwd()\n",
    "    images_path = project_path +  '/8DM20_image_dataset/' + data_set + '/' + image + '/'\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    #Open image for image (20 in total for each of them)\n",
    "    for i in range(1, 21):\n",
    "        \n",
    "        # Find correct image number\n",
    "        image_nr = str(i)\n",
    "        if data_set == 'training':\n",
    "            image_nr = str(20 + i)\n",
    "        elif len(image_nr) == 1:\n",
    "            image_nr = '0' + image_nr\n",
    "            \n",
    "        # Specify path for this image\n",
    "        if image == '1st_manual':\n",
    "            image_path = images_path + image_nr + '_manual1.gif'\n",
    "        elif image == '2nd_manual':\n",
    "            image_path = images_path + image_nr + '_manual2.gif'\n",
    "        elif image == 'images':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '.tif'\n",
    "        elif image == 'mask':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '_mask.gif'\n",
    "        \n",
    "        # Open and append the image to the image list\n",
    "        images.append(PIL_image.open(image_path))\n",
    "        \n",
    "    return images\n",
    "\n",
    "#The function that converts the channels in the images from RGB to gray\n",
    "#and makes matrices from the images\n",
    "def convertImageToMatrix(images):\n",
    "    \n",
    "    image_matrices = []\n",
    "    \n",
    "    for image in images:\n",
    "        image_matrix = np.asarray(image.convert('L'))\n",
    "        image_matrices.append(image_matrix)\n",
    "        \n",
    "    return image_matrices\n",
    "\n",
    "#The function that prepares the image matrices to the data used for machine learning\n",
    "def prepareMachineLearningData(image_matrix, output_matrix, mask_matrix, kernel_size, mask_removal = 'pixel'):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrix, np.ndarray) and \n",
    "            isinstance(output_matrix, np.ndarray) and \n",
    "            isinstance(mask_matrix, np.ndarray)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if mask_removal != 'pixel' and mask_removal != 'patch':\n",
    "        raise Exception(\"Unknown mask data removal type\")\n",
    "    \n",
    "    if not (image_matrix.shape == output_matrix.shape == mask_matrix.shape):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    if np.unique(mask_matrix).shape[0] != 2:\n",
    "        raise Exception(\"The mask matrix does not consist of only 2 values\")\n",
    "    \n",
    "    #Creates a matrix with all possible patches\n",
    "    all_image_patches = sklearn_image.extract_patches_2d(image_matrix,(kernel_size,kernel_size))\n",
    "    all_image_patches = np.expand_dims(all_image_patches, axis=1)\n",
    "    \n",
    "    if kernel_size % 2 != 0:\n",
    "         # Creates an array with all output\n",
    "        mat_red = (kernel_size - 1) / 2\n",
    "        reduced_output_matrix = output_matrix[ mat_red : -  mat_red,  mat_red : -  mat_red]\n",
    "        complete_output_array = reduced_output_matrix.reshape(-1)\n",
    "\n",
    "        new_mask_matrix = mask_matrix.copy()\n",
    "        \n",
    "        # Makes some additional mask values zero on the edge of the mask\n",
    "        if mask_removal == 'patch':\n",
    "            for i in range(mat_red, mask_matrix.shape[0] -  mat_red + 1):\n",
    "                for j in range(mat_red, mask_matrix.shape[1] -  mat_red + 1):\n",
    "                    if 0 in mask_matrix[i - mat_red : i + mat_red + 1, j - mat_red: j + mat_red + 1]:\n",
    "                        new_mask_matrix[i,j] = 0;\n",
    "        \n",
    "        # Creates an array with all mask locations\n",
    "        reduced_mask_matrix = new_mask_matrix[ mat_red : -  mat_red, mat_red : -  mat_red]\n",
    "        mask_array = reduced_mask_matrix.reshape(-1)\n",
    "    \n",
    "    else:\n",
    "        # Creates an array with all output\n",
    "        mat_red = (kernel_size) / 2\n",
    "        reduced_output_matrix = output_matrix[mat_red - 1: -  mat_red,  mat_red - 1: -  mat_red]\n",
    "        complete_output_array = reduced_output_matrix.reshape(-1)\n",
    "\n",
    "        new_mask_matrix = mask_matrix.copy()\n",
    "        \n",
    "        # Makes some additional mask values zero on the edge of the mask\n",
    "        if mask_removal == 'patch':\n",
    "            for i in range(mat_red - 1, mask_matrix.shape[0] -  mat_red - 1):\n",
    "                for j in range(mat_red - 1, mask_matrix.shape[1] -  mat_red - 1):\n",
    "                    if 0 in mask_matrix[i - mat_red + 1 : i + mat_red + 1, j - mat_red + 1: j + mat_red + 1]:\n",
    "                        new_mask_matrix[i,j] = 0;\n",
    "                     \n",
    "        # Creates an array with all mask locations\n",
    "        reduced_mask_matrix = new_mask_matrix[mat_red - 1: - mat_red, mat_red - 1: - mat_red]\n",
    "        mask_array = reduced_mask_matrix.reshape(-1) \n",
    "\n",
    "    image_patches = []\n",
    "    output_array = []    \n",
    "    \n",
    "    # Reduces the number of patches and output to only the mask values\n",
    "    for i in range(len(mask_array)):\n",
    "        if mask_array[i] != 0:\n",
    "            image_patches.append(all_image_patches[i,:,:])\n",
    "            output_array.append(complete_output_array[i])\n",
    "    \n",
    "    # Return the image patches and the output array\n",
    "    return image_patches, output_array\n",
    "\n",
    "# Prepare multiple images at once\n",
    "def prepareMultipleImages(image_matrices, output_matrices, mask_matrices, kernel_size = 25, mask_removal = 'pixel'):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrices, list) and \n",
    "            isinstance(output_matrices, list) and \n",
    "            isinstance(mask_matrices, list)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if not (len(image_matrices) == len(output_matrices) == len(mask_matrices)):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    image_patches = [] \n",
    "    output_arrays = []\n",
    "    \n",
    "    # Finds the output data per image\n",
    "    for i in range(len(image_matrices)):\n",
    "        new_image_patches, new_output_array = prepareMachineLearningData(image_matrices[i], output_matrices[i], mask_matrices[i], \n",
    "                                                                         kernel_size = kernel_size, mask_removal = mask_removal)\n",
    "        image_patches.append(new_image_patches)\n",
    "        output_arrays.append(new_output_array)\n",
    "        \n",
    "        #Print progress for showing time consumption\n",
    "        print\"Progress: {} %\".format(100*(i+1)/len(image_matrices)),\n",
    "              \n",
    "    return image_patches, output_arrays\n",
    "\n",
    "def createVesselImage(output_array, mask_matrix, kernel_size, mask_removal = \"pixel\"):\n",
    "    #Check if input is correct\n",
    "    if not isinstance(output_array, list) or not isinstance(mask_matrix, np.ndarray) or not isinstance(kernel_size, int):\n",
    "        raise Exception(\"Not the right input variables\")\n",
    "    \n",
    "    if mask_removal != \"pixel\" and mask_removal != 'patch':\n",
    "        raise Exception(\"Unknown mask removal type\")\n",
    "    \n",
    "    #Create an output_matrix for the output array\n",
    "    #output_matrix = np.array(mask_matrix)\n",
    "    output_matrix = np.zeros(mask_matrix.shape)\n",
    "    output_loc = 0\n",
    "    \n",
    "    # Take into account that mask pixels too close to the border are lost due to inability to make patches\n",
    "    edge_corr = int(math.ceil(kernel_size / 2) - 1)\n",
    "    \n",
    "    new_mask_matrix = mask_matrix.copy()\n",
    "    \n",
    "    # Makes some additional mask values zero on the edge of the mask\n",
    "    if mask_removal == 'patch':\n",
    "        for i in range(edge_corr, mask_matrix.shape[0] - edge_corr - 2):\n",
    "            for j in range(edge_corr, mask_matrix.shape[1] - edge_corr - 2):\n",
    "                if 0 in mask_matrix[i - edge_corr  : i + edge_corr + 2, j - edge_corr: j + edge_corr + 2]:\n",
    "                    new_mask_matrix[i,j] = 0;\n",
    "       \n",
    "    # Check every pixel within the mask for a vessel pixel\n",
    "    for i in range(mask_matrix.shape[0] - kernel_size + 1):\n",
    "        for j in range(mask_matrix.shape[1] - kernel_size + 1):\n",
    "            if new_mask_matrix[i + edge_corr, j + edge_corr] == 255:\n",
    "                output_matrix[i + edge_corr, j + edge_corr] = output_array[output_loc]\n",
    "                output_loc += 1\n",
    "                \n",
    "    return output_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are loaded and immediately made into matrices for further computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All test image lists\n",
    "test_manual1_images = loadData('test', '1st_manual')\n",
    "test_manual2_images = loadData('test', '2nd_manual')\n",
    "test_raw_images = loadData('test', 'images')\n",
    "test_mask_images = loadData('test', 'mask')\n",
    "\n",
    "# Making matrices of the test images to work with\n",
    "test_manual1_matrices = convertImageToMatrix(test_manual1_images)\n",
    "test_manual2_matrices = convertImageToMatrix(test_manual2_images)\n",
    "test_raw_matrices = convertImageToMatrix(test_raw_images)\n",
    "test_mask_matrices = convertImageToMatrix(test_mask_images)\n",
    "\n",
    "# All training image lists\n",
    "training_manual1_images = loadData('training', '1st_manual')\n",
    "training_raw_images = loadData('training', 'images')\n",
    "training_mask_images = loadData('training', 'mask')\n",
    "\n",
    "# Making matrices of the training images to work with\n",
    "training_manual1_matrices = convertImageToMatrix(training_manual1_images)\n",
    "training_raw_matrices = convertImageToMatrix(training_raw_images)\n",
    "training_mask_matrices = convertImageToMatrix(training_mask_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrices are then used for further preprocessing to retrieve the suitable data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of good patches according to mask array is 193342\n",
      "Length output array is 193342\n",
      "Progress: 50 % Number of good patches according to mask array is 195382\n",
      "Length output array is 195382\n",
      "Progress: 100 % Number of good patches according to mask array is 192286\n",
      "Length output array is 192286\n",
      "Progress: 100 %\n"
     ]
    }
   ],
   "source": [
    "#Choose the number of images\n",
    "nr_images_training = 2\n",
    "nr_images_test = 1\n",
    "\n",
    "# Prepares the data for machine learning: X = image_patches, y = output_array\n",
    "# Both are a list with the patches and output_arrays for multiple images (the number chosen before)\n",
    "image_patches, output_array = prepareMultipleImages(training_raw_matrices[0:nr_images_training], training_manual1_matrices[0:nr_images_training], \n",
    "                                                     training_mask_matrices[0:nr_images_training], 32, mask_removal = 'patch')\n",
    "test_image_patches, test_output_array = prepareMultipleImages(test_raw_matrices[0:nr_images_test], test_manual1_matrices[0:nr_images_test], \n",
    "                                                     test_mask_matrices[0:nr_images_test], 32, mask_removal = 'patch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Algorithm setup</h4>\n",
    "The following algorithms are to show how the data set is built up. There are patches of 32x 32. These values either correspond to a vene pixel or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_validation_set(image_patches, output_array):\n",
    "    all_train_patches = []\n",
    "    all_train_output = []\n",
    "\n",
    "    for i in range(nr_images_training):\n",
    "        if i <= (nr_images_training-1)/2 :\n",
    "            for j in range(len(image_patches[i])):\n",
    "                all_train_patches.append(image_patches[i][j])\n",
    "                all_train_output.append(output_array[i][j])\n",
    "        else:\n",
    "            valid_patches = image_patches[i]\n",
    "            valid_output = output_array[i]\n",
    "    \n",
    "    return all_train_patches, all_train_output, valid_patches, valid_output\n",
    "\n",
    "def hot_encoding(all_train_output, valid_output):\n",
    "    train_hot_output = np.zeros((len(all_train_output),2),dtype=np.int16)\n",
    "\n",
    "    # Make hot encoding training set\n",
    "    for i in range(len(train_hot_output)):\n",
    "        if all_train_output[i] == 0:\n",
    "            train_hot_output[i,0] = 1\n",
    "        else:\n",
    "            train_hot_output[i,1] = 1      \n",
    "\n",
    "    # Make hot encoding validation set\n",
    "    valid_hot_output = np.zeros((len(valid_output),2),dtype=np.int16)\n",
    "\n",
    "    for i in range(len(valid_hot_output)):\n",
    "        if valid_output[i] == 0:\n",
    "            valid_hot_output[i,0] = 1\n",
    "        else:\n",
    "            valid_hot_output[i,1] = 1\n",
    "    \n",
    "    return train_hot_output, valid_hot_output\n",
    "\n",
    "\n",
    "def test_set(test_image_patches, test_output_array):\n",
    "    all_test_patches = []\n",
    "    all_test_output_array = []\n",
    "    \n",
    "    for i in range(nr_images_test):\n",
    "        for j in range(len(test_image_patches[i])):\n",
    "            all_test_patches.append(test_image_patches[i][j])\n",
    "            all_test_output_array.append(test_output_array[i][j])\n",
    "                \n",
    "    return all_test_patches, all_test_output_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to first make the output array. This is done with hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_train_patches, all_train_output, valid_patches, valid_output = train_and_validation_set(image_patches, output_array)\n",
    "train_hot_output, valid_hot_output = hot_encoding(all_train_output, valid_output)\n",
    "\n",
    "all_test_patches, all_test_output_array = test_set(test_image_patches, test_output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the LeNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildLeNet(X1):\n",
    "    inputlayer = lasagne.layers.InputLayer(shape=(None, 1, 32, 32),input_var=X1)    \n",
    "    print inputlayer.output_shape\n",
    "    \n",
    "    layer1 = lasagne.layers.Conv2DLayer(inputlayer, num_filters=6, filter_size=(5,5), nonlinearity=lasagne.nonlinearities.rectify, W=lasagne.init.GlorotUniform())\n",
    "    print layer1.output_shape \n",
    "    \n",
    "    layer2 = lasagne.layers.MaxPool2DLayer(layer1, pool_size=(2, 2))\n",
    "    print layer2.output_shape \n",
    "    \n",
    "    layer3 = lasagne.layers.Conv2DLayer(layer2, num_filters=16, filter_size=(5,5), nonlinearity=lasagne.nonlinearities.rectify, W=lasagne.init.GlorotUniform())\n",
    "    print layer3.output_shape \n",
    "    \n",
    "    layer4 = lasagne.layers.MaxPool2DLayer(layer3, pool_size=(2, 2))\n",
    "    print layer4.output_shape \n",
    "    \n",
    "    layer4 = lasagne.layers.flatten(layer4)\n",
    "    print layer4.output_shape \n",
    "    \n",
    "    layer5 = lasagne.layers.DenseLayer(layer4,num_units=120,nonlinearity=lasagne.nonlinearities.rectify)    \n",
    "    print layer5.output_shape \n",
    "    \n",
    "    layer6 = lasagne.layers.DenseLayer(layer5,num_units=84,nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    print layer6.output_shape \n",
    "    \n",
    "    outputlayer = lasagne.layers.DenseLayer(layer6,num_units=2,nonlinearity=lasagne.nonlinearities.softmax)     \n",
    "    print outputlayer.output_shape \n",
    "    \n",
    "    return layer1, layer2, layer3, layer4, layer5, layer6, outputlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 32, 32)\n",
      "(None, 6, 28, 28)\n",
      "(None, 6, 14, 14)\n",
      "(None, 16, 10, 10)\n",
      "(None, 16, 5, 5)\n",
      "(None, 400)\n",
      "(None, 120)\n",
      "(None, 84)\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "X = theano.tensor.tensor4()\n",
    "Y = theano.tensor.matrix()\n",
    "layer1, layer2, layer3, layer4, layer5, layer6, outputlayer = buildLeNet(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions for training, validation and testing purposes for the previously made LeNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputtrain = lasagne.layers.get_output(outputlayer) #function that gets the output from the network defined before.\n",
    "trainloss = lasagne.objectives.categorical_crossentropy(outputtrain, Y).mean() #function that computes the mean crossentropy between the output and the real labels.\n",
    "params = lasagne.layers.get_all_params(outputlayer, trainable=True) #function that gets all the parameters (weights) in the network.\n",
    "updates = lasagne.updates.momentum(trainloss, params, learning_rate=0.001) #function that performs an update of the weights based on the loss.\n",
    "train = theano.function(inputs=[X, Y], outputs=trainloss, updates=updates, allow_input_downcast=True) #function that does all the above based on training samples X and real labels Y.\n",
    "\n",
    "validate = theano.function(inputs=[X, Y], outputs=trainloss, allow_input_downcast=True) #function that computes the loss without performing an update\n",
    "\n",
    "outputtest = lasagne.layers.get_output(outputlayer, deterministic=True) #function that gets the output from the network defined before.\n",
    "test = theano.function(inputs=[X], outputs=outputtest, allow_input_downcast=True) #function that gets the output based on input X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training_the_network(all_train_output, valid_output, all_train_patches, valid_patches, minibatches = 250, minibatchsize = 100):\n",
    "\n",
    "    trainingsamples = np.arange(len(all_train_output)) #numbers from 0 until the number of samples\n",
    "    validsamples = np.arange(len(valid_output))\n",
    "\n",
    "    losslist = []\n",
    "    validlosslist = []\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    for i in xrange(minibatches):\n",
    "        print(\"Currently at batch %d\" % i)\n",
    "\n",
    "        # Random train sample information. IMPORTANT: Use the hot encoded labels (that's the way the algorithm works)\n",
    "        random_train_patches, random_train_output = sampleBatches(all_train_patches, all_train_output, \n",
    "                                                                  batch_size = minibatchsize, distribution = 0.5)\n",
    "\n",
    "        # Random validation sample information IMPORTANT: Use the hot encoded labels (that's the way the algorithm works)\n",
    "        random_valid_patches, random_valid_output = sampleBatches(valid_patches, valid_output, \n",
    "                                                                  batch_size = minibatchsize, distribution = 0.5)\n",
    "\n",
    "        new_train_loss = train(random_train_patches, random_train_output)\n",
    "        losslist.append(new_train_loss)\n",
    "\n",
    "        new_valid_loss = validate(random_valid_patches, random_valid_output)\n",
    "        validlosslist.append(new_valid_loss)\n",
    "        #select random training en validation samples and perform training and validation steps here.\n",
    "\n",
    "    t1 = time.time()\n",
    "    print 'Training time: {} seconds'.format(t1-t0)\n",
    "    \n",
    "    return losslist, validlosslist\n",
    "\n",
    "\n",
    "# Creates bathces of vessel and non vessel images of a certain distribution\n",
    "def sampleBatches(input_patches, output_array, batch_size = 100, distribution = 0.5):\n",
    "    if len(input_patches) != len(output_array):\n",
    "        raise Exception(\"Length of input and output is different\")\n",
    "    \n",
    "    if distribution < 0 or distribution > 1:\n",
    "        raise Exception(\"Impossible distribution\")\n",
    "        \n",
    "    non_vessel_patches = []\n",
    "    vessel_patches = []\n",
    "    \n",
    "    #First create two lists. One with vessel patches and one without\n",
    "    for i in range(len(input_patches)):\n",
    "        if output_array[i] == 0:\n",
    "            non_vessel_patches.append(input_patches[i])\n",
    "            \n",
    "        else:\n",
    "            vessel_patches.append(input_patches[i])\n",
    "            \n",
    "    # Choose non vessel patches for in the batch\n",
    "    samples_non_vessel = np.arange(len(non_vessel_patches)) #numbers from 0 until the number of samples\n",
    "    random_non_vessel_samples = random.sample(samples_non_vessel, int(batch_size * distribution))\n",
    "    non_vessel_output = int(batch_size * distribution) * [[1, 0]]\n",
    "    non_vessel_patches = np.asarray(non_vessel_patches)[random_non_vessel_samples]\n",
    "    \n",
    "    # Choose vessel patches for in the batch\n",
    "    samples_vessel = np.arange(len(vessel_patches)) #numbers from 0 until the number of samples\n",
    "    random_vessel_samples = random.sample(samples_vessel, int(batch_size * (1 - distribution)))\n",
    "    vessel_output = int(batch_size * (1 - distribution)) * [[0, 1]]\n",
    "    vessel_patches = np.asarray(vessel_patches)[random_vessel_samples]\n",
    "             \n",
    "    # Combine the batches    \n",
    "    batch_patches = np.append(non_vessel_patches, vessel_patches, axis = 0)\n",
    "    batch_output = np.append(non_vessel_output, vessel_output, axis = 0)\n",
    "                                          \n",
    "    return batch_patches, batch_output\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at batch 0\n",
      "Currently at batch 1\n",
      "Currently at batch 2\n",
      "Currently at batch 3\n",
      "Currently at batch 4\n",
      "Currently at batch 5\n",
      "Currently at batch 6\n",
      "Currently at batch 7\n",
      "Currently at batch 8\n",
      "Currently at batch 9\n",
      "Currently at batch 10\n",
      "Currently at batch 11\n",
      "Currently at batch 12\n",
      "Currently at batch 13\n",
      "Currently at batch 14\n",
      "Currently at batch 15\n",
      "Currently at batch 16\n",
      "Currently at batch 17\n",
      "Currently at batch 18\n",
      "Currently at batch 19\n",
      "Currently at batch 20\n",
      "Currently at batch 21\n",
      "Currently at batch 22\n",
      "Currently at batch 23\n",
      "Currently at batch 24\n",
      "Currently at batch 25\n",
      "Currently at batch 26\n",
      "Currently at batch 27\n",
      "Currently at batch 28\n",
      "Currently at batch 29\n",
      "Training time: 179.51699996 seconds\n"
     ]
    }
   ],
   "source": [
    "losslist, validlosslist = training_the_network(all_train_output, valid_output, all_train_patches, valid_patches, minibatches = 30, minibatchsize = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEdwjnpAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4e40def0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losslist)\n",
    "plt.plot(validlosslist)\n",
    "plt.legend(['Training loss','Validation loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]\n",
      " [ 0.49716239  0.50283761]]\n",
      "Testing time: 0.145999908447 seconds\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "testing = test(all_test_patches[0:100])\n",
    "print(testing)\n",
    "test_set_predictions = np.argmax(testing, axis = 1)\n",
    "t1 = time.time()\n",
    "print 'Testing time: {} seconds'.format(t1-t0)\n",
    "\n",
    "print test_set_predictions\n",
    "print sum(test_set_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57621L, 6L, 28L, 28L)\n"
     ]
    }
   ],
   "source": [
    "outputlayer1 = lasagne.layers.get_output(layer1) \n",
    "outputfeatures = theano.function(inputs=[X], outputs=outputlayer1, allow_input_downcast=True) \n",
    "\n",
    "features = outputfeatures(all_test_patches[1000:58621])\n",
    "print np.shape(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57621L, 6L, 28L, 28L)\n"
     ]
    }
   ],
   "source": [
    "print features.shape\n",
    "for i in xrange(6):\n",
    "    plt.figure()\n",
    "    plt.imshow(features[1,i],cmap='gray_r',interpolation='none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
