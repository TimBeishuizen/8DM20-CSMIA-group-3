{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep learning project 8DM20 CSMIA</h1>\n",
    "\n",
    "<h4>Group members:</h4>\n",
    "O. Akdag - 0842508 <br>\n",
    "T.P.A. Beishuizen - 0791613 <br>\n",
    "A.S.A. Eskelinen - 1224333 <br>\n",
    "J.H.A. Migchielsen - 0495058 <br>\n",
    "L. van den Wildenberg - 0844697 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import all used packages (unused packages are commented out so far)\n",
    "import os\n",
    "from PIL import Image as PIL_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from sklearn.feature_extraction import image as sklearn_image\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "#matplotlib inline\n",
    "import theano\n",
    "import lasagne\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import cPickle\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Preprocessing</h4>\n",
    "\n",
    "Before every thing can be done, at first the data images have to be read and be made in useable data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function that loads the data\n",
    "def loadData(data_set = 'test', image = '1st_manual'):\n",
    "    \n",
    "    # Check for the correct input\n",
    "    if data_set != 'test' and data_set != 'training':\n",
    "        raise Exception('Not the right data_set file')\n",
    "    if image != '1st_manual' and image != '2nd_manual' and image != 'images' and image != 'mask':\n",
    "        raise Exception('Not the right image file')\n",
    "    if data_set == 'training' and image == '2nd_manual':\n",
    "        raise Exception('File not available')\n",
    "    \n",
    "    # Project and image path\n",
    "    project_path = os.getcwd()\n",
    "    images_path = project_path +  '/8DM20_image_dataset/' + data_set + '/' + image + '/'\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    #Open image for image (20 in total for each of them)\n",
    "    for i in range(1, 21):\n",
    "        \n",
    "        # Find correct image number\n",
    "        image_nr = str(i)\n",
    "        if data_set == 'training':\n",
    "            image_nr = str(20 + i)\n",
    "        elif len(image_nr) == 1:\n",
    "            image_nr = '0' + image_nr\n",
    "            \n",
    "        # Specify path for this image\n",
    "        if image == '1st_manual':\n",
    "            image_path = images_path + image_nr + '_manual1.gif'\n",
    "        elif image == '2nd_manual':\n",
    "            image_path = images_path + image_nr + '_manual2.gif'\n",
    "        elif image == 'images':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '.tif'\n",
    "        elif image == 'mask':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '_mask.gif'\n",
    "        \n",
    "        # Open and append the image to the image list\n",
    "        images.append(PIL_image.open(image_path))\n",
    "        \n",
    "    return images\n",
    "\n",
    "#The function that converts the channels in the images from RGB to gray\n",
    "#and makes matrices from the images\n",
    "def convertImageToMatrix(images):\n",
    "    \n",
    "    image_matrices = []\n",
    "    \n",
    "    for image in images:\n",
    "        image_matrix = np.asarray(image.convert('RGB'))\n",
    "        green_image_matrix = image_matrix[:,:,1]\n",
    "        image_matrices.append(green_image_matrix)\n",
    "        \n",
    "    return image_matrices\n",
    "\n",
    "#The function that prepares the image matrices to the data used for machine learning\n",
    "def prepareMachineLearningData(image_matrix, output_matrix, mask_matrix, kernel_size, mask_removal = 'pixel'):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrix, np.ndarray) and \n",
    "            isinstance(output_matrix, np.ndarray) and \n",
    "            isinstance(mask_matrix, np.ndarray)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if mask_removal != 'pixel' and mask_removal != 'patch':\n",
    "        raise Exception(\"Unknown mask data removal type\")\n",
    "    \n",
    "    if not (image_matrix.shape == output_matrix.shape == mask_matrix.shape):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    if np.unique(mask_matrix).shape[0] != 2:\n",
    "        raise Exception(\"The mask matrix does not consist of only 2 values\")\n",
    "    \n",
    "    # Matrix reduction\n",
    "    mat_red = kernel_size / 2\n",
    "    \n",
    "    # Makes some additional mask values zero on the edge of the mask\n",
    "    new_mask_matrix = mask_matrix.copy()\n",
    "    \n",
    "    image_patches = []\n",
    "    output_array = []\n",
    "    \n",
    "    # Remove patch pixels with masks\n",
    "    if mask_removal == 'patch':\n",
    "        for i in range(mat_red - 1, mask_matrix.shape[0] - mat_red):\n",
    "            for j in range(mat_red - 1, mask_matrix.shape[1] - mat_red):\n",
    "                if 0 in mask_matrix[i - mat_red + 1: i + mat_red + 1, j - mat_red + 1: j + mat_red + 1]:\n",
    "                    new_mask_matrix[i,j] = 0;\n",
    "    \n",
    "    # Append the patches append the output\n",
    "    for i in range(mat_red - 1, mask_matrix.shape[0] - mat_red):\n",
    "        for j in range(mat_red - 1, mask_matrix.shape[1] - mat_red):\n",
    "            if new_mask_matrix[i][j] > 0:\n",
    "                image_patches.append(image_matrix[i - mat_red + 1: i + mat_red + 1, j - mat_red + 1: j + mat_red + 1])\n",
    "                output_array.append(output_matrix[i][j])\n",
    "    \n",
    "    # Make the image have the right dimensions\n",
    "    corr_image_patches = np.expand_dims(image_patches, axis=1)\n",
    "    \n",
    "    return corr_image_patches, output_array\n",
    "\n",
    "# Prepare multiple images at once\n",
    "def prepareMultipleImages(image_matrices, output_matrices, mask_matrices, kernel_size = 25, mask_removal = 'pixel'):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrices, list) and \n",
    "            isinstance(output_matrices, list) and \n",
    "            isinstance(mask_matrices, list)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if not (len(image_matrices) == len(output_matrices) == len(mask_matrices)):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    image_patches = [] \n",
    "    output_arrays = []\n",
    "    \n",
    "    # Finds the output data per image\n",
    "    for i in range(len(image_matrices)):\n",
    "        new_image_patches, new_output_array = prepareMachineLearningData(image_matrices[i], output_matrices[i], mask_matrices[i], \n",
    "                                                                         kernel_size = kernel_size, mask_removal = mask_removal)\n",
    "        image_patches.append(new_image_patches)\n",
    "        output_arrays.append(new_output_array)\n",
    "        \n",
    "        #Print progress for showing time consumption\n",
    "        print\"Progress: {} %\".format(100*(i+1)/len(image_matrices)),\n",
    "              \n",
    "    return image_patches, output_arrays\n",
    "\n",
    "def createVesselImage(output_array, mask_matrix, kernel_size, mask_removal = \"pixel\"):\n",
    "    #Check if input is correct\n",
    "    if not isinstance(output_array, list) or not isinstance(mask_matrix, np.ndarray) or not isinstance(kernel_size, int):\n",
    "        raise Exception(\"Not the right input variables\")\n",
    "    \n",
    "    if mask_removal != \"pixel\" and mask_removal != 'patch':\n",
    "        raise Exception(\"Unknown mask removal type\")\n",
    "    \n",
    "    #Create an output_matrix for the output array\n",
    "    #output_matrix = np.array(mask_matrix)\n",
    "    output_matrix = np.zeros(mask_matrix.shape)\n",
    "    output_loc = 0\n",
    "    \n",
    "    # Take into account that mask pixels too close to the border are lost due to inability to make patches\n",
    "    edge_corr = int(math.ceil(kernel_size / 2) - 1)\n",
    "    \n",
    "    new_mask_matrix = mask_matrix.copy()\n",
    "    \n",
    "    # Makes some additional mask values zero on the edge of the mask\n",
    "    if mask_removal == 'patch':\n",
    "        for i in range(edge_corr, mask_matrix.shape[0] - edge_corr - 2):\n",
    "            for j in range(edge_corr, mask_matrix.shape[1] - edge_corr - 2):\n",
    "                if 0 in mask_matrix[i - edge_corr  : i + edge_corr + 2, j - edge_corr: j + edge_corr + 2]:\n",
    "                    new_mask_matrix[i,j] = 0;\n",
    "       \n",
    "    # Check every pixel within the mask for a vessel pixel\n",
    "    for i in range(mask_matrix.shape[0] - kernel_size + 1):\n",
    "        for j in range(mask_matrix.shape[1] - kernel_size + 1):\n",
    "            if new_mask_matrix[i + edge_corr, j + edge_corr] == 255:\n",
    "                output_matrix[i + edge_corr, j + edge_corr] = output_array[output_loc]\n",
    "                output_loc += 1\n",
    "                \n",
    "    return output_matrix \n",
    "\n",
    "def train_and_validation_set(image_patches, output_array):\n",
    "    all_train_patches = []\n",
    "    all_train_output = []\n",
    "    \n",
    "    # Make an array with the patches and the last one is the validation image\n",
    "    for i in range(nr_images_training - 1):\n",
    "        for j in range(len(image_patches[i])):\n",
    "            all_train_patches.append(image_patches[i][j])\n",
    "            all_train_output.append(output_array[i][j])\n",
    "\n",
    "    valid_patches = image_patches[nr_images_training - 1]\n",
    "    valid_output = output_array[nr_images_training - 1]\n",
    "    \n",
    "    return all_train_patches, all_train_output, valid_patches, valid_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are loaded and immediately made into matrices for further computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All test image lists\n",
    "test_manual1_images = loadData('test', '1st_manual')\n",
    "test_manual2_images = loadData('test', '2nd_manual')\n",
    "test_raw_images = loadData('test', 'images')\n",
    "test_mask_images = loadData('test', 'mask')\n",
    "\n",
    "# Making matrices of the test images to work with\n",
    "test_manual1_matrices = convertImageToMatrix(test_manual1_images)\n",
    "test_manual2_matrices = convertImageToMatrix(test_manual2_images)\n",
    "test_raw_matrices = convertImageToMatrix(test_raw_images)\n",
    "test_mask_matrices = convertImageToMatrix(test_mask_images)\n",
    "\n",
    "# All training image lists\n",
    "training_manual1_images = loadData('training', '1st_manual')\n",
    "training_raw_images = loadData('training', 'images')\n",
    "training_mask_images = loadData('training', 'mask')\n",
    "\n",
    "# Making matrices of the training images to work with\n",
    "training_manual1_matrices = convertImageToMatrix(training_manual1_images)\n",
    "training_raw_matrices = convertImageToMatrix(training_raw_images)\n",
    "training_mask_matrices = convertImageToMatrix(training_mask_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrices are then used for further preprocessing to retrieve the suitable data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 25 % Progress: 50 % Progress: 75 % Progress: 100 % Progress: 100 %\n"
     ]
    }
   ],
   "source": [
    "#Choose the number of images\n",
    "nr_images_training = 4\n",
    "nr_images_test = 1\n",
    "\n",
    "# Prepares the data for machine learning: X = image_patches, y = output_array\n",
    "# Both are a list with the patches and output_arrays for multiple images (the number chosen before)\n",
    "image_patches, output_array = prepareMultipleImages(training_raw_matrices[0:nr_images_training], training_manual1_matrices[0:nr_images_training], \n",
    "                training_mask_matrices[0:nr_images_training], 32, mask_removal = 'patch')\n",
    "test_image_patches, test_output_array = prepareMultipleImages(test_raw_matrices[0:nr_images_test], test_manual1_matrices[0:nr_images_test], \n",
    "                                                     test_mask_matrices[0:nr_images_test], 32, mask_removal = 'patch')\n",
    "\n",
    "\n",
    "#Divde patches and output in training and validation images\n",
    "all_train_patches, all_train_output, valid_patches, valid_output = train_and_validation_set(image_patches, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Algorithm setup</h4>\n",
    "Build the LeNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildLeNet(X1):\n",
    "    inputlayer = lasagne.layers.InputLayer(shape=(None, 1, 32, 32),input_var=X1)    \n",
    "    print inputlayer.output_shape\n",
    "    \n",
    "    layer1 = lasagne.layers.Conv2DLayer(inputlayer, num_filters=6, filter_size=(5,5), nonlinearity=lasagne.nonlinearities.sigmoid, W=lasagne.init.GlorotUniform())\n",
    "    print layer1.output_shape \n",
    "    \n",
    "    layer2 = lasagne.layers.MaxPool2DLayer(layer1, pool_size=(2, 2))\n",
    "    print layer2.output_shape \n",
    "    \n",
    "    layer3 = lasagne.layers.Conv2DLayer(layer2, num_filters=16, filter_size=(5,5), nonlinearity=lasagne.nonlinearities.sigmoid, W=lasagne.init.GlorotUniform())\n",
    "    print layer3.output_shape \n",
    "    \n",
    "    layer4 = lasagne.layers.MaxPool2DLayer(layer3, pool_size=(2, 2))\n",
    "    print layer4.output_shape \n",
    "    \n",
    "    layer4 = lasagne.layers.flatten(layer4)\n",
    "    print layer4.output_shape \n",
    "    \n",
    "    layer5 = lasagne.layers.DenseLayer(layer4,num_units=120,nonlinearity=lasagne.nonlinearities.sigmoid)    \n",
    "    print layer5.output_shape \n",
    "    \n",
    "    layer6 = lasagne.layers.DenseLayer(layer5,num_units=84,nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "    print layer6.output_shape \n",
    "    \n",
    "    outputlayer = lasagne.layers.DenseLayer(layer6,num_units=2,nonlinearity=lasagne.nonlinearities.softmax)     \n",
    "    print outputlayer.output_shape \n",
    "    \n",
    "    return layer1, layer2, layer3, layer4, layer5, layer6, outputlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 32, 32)\n",
      "(None, 6, 28, 28)\n",
      "(None, 6, 14, 14)\n",
      "(None, 16, 10, 10)\n",
      "(None, 16, 5, 5)\n",
      "(None, 400)\n",
      "(None, 120)\n",
      "(None, 84)\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "X = theano.tensor.tensor4()\n",
    "Y = theano.tensor.matrix()\n",
    "layer1, layer2, layer3, layer4, layer5, layer6, outputlayer = buildLeNet(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions for training, validation and testing purposes for the previously made LeNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputtrain = lasagne.layers.get_output(outputlayer) #function that gets the output from the network defined before.\n",
    "trainloss = lasagne.objectives.categorical_crossentropy(outputtrain, Y).mean() #function that computes the mean crossentropy between the output and the real labels.\n",
    "params = lasagne.layers.get_all_params(outputlayer, trainable=True) #function that gets all the parameters (weights) in the network.\n",
    "updates = lasagne.updates.momentum(trainloss, params, learning_rate=0.001) #function that performs an update of the weights based on the loss.\n",
    "train = theano.function(inputs=[X, Y], outputs=trainloss, updates=updates, allow_input_downcast=True) #function that does all the above based on training samples X and real labels Y.\n",
    "\n",
    "validate = theano.function(inputs=[X, Y], outputs=trainloss, allow_input_downcast=True) #function that computes the loss without performing an update\n",
    "\n",
    "outputtest = lasagne.layers.get_output(outputlayer, deterministic=True) #function that gets the output from the network defined before.\n",
    "test = theano.function(inputs=[X], outputs=outputtest, allow_input_downcast=True) #function that gets the output based on input X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training_the_network(all_train_output, valid_output, all_train_patches, valid_patches, minibatches = 250, minibatchsize = 100):\n",
    "\n",
    "    #Recieve vessel and non-vessel patches\n",
    "    train_non_vessel_patches = []\n",
    "    train_vessel_patches = []\n",
    "    \n",
    "    #First create two training lists. One with vessel patches and one without\n",
    "    for i in range(len(all_train_output)):\n",
    "        if all_train_output[i] == 0:\n",
    "            train_non_vessel_patches.append(all_train_patches[i])          \n",
    "        else:\n",
    "            train_vessel_patches.append(all_train_patches[i])\n",
    "    \n",
    "    valid_non_vessel_patches = []\n",
    "    valid_vessel_patches = []\n",
    "    \n",
    "    #Second create two valid lists. One with vessel patches and one without\n",
    "    for i in range(len(valid_output)):\n",
    "        if valid_output[i] == 0:\n",
    "            valid_non_vessel_patches.append(valid_patches[i])          \n",
    "        else:\n",
    "            valid_vessel_patches.append(valid_patches[i])\n",
    "    \n",
    "    #Create, train and validate the patches\n",
    "    t0 = time.time()\n",
    "    losslist = []\n",
    "    validlosslist = []\n",
    "    \n",
    "    for i in xrange(minibatches):\n",
    "\n",
    "        # Random train sample information. IMPORTANT: Use the hot encoded labels (that's the way the algorithm works)\n",
    "        random_train_patches, random_train_output = sampleBatches(train_non_vessel_patches, train_vessel_patches, \n",
    "                                                                  batch_size = minibatchsize, distribution = 0.5)\n",
    "\n",
    "        #print(\"image without vessels: %d\" % (random_train_output[0][0]))\n",
    "        #plt.imshow(random_train_patches[0][0])\n",
    "        #plt.show()\n",
    "        #print(\"image with vessels: %d\" % (random_train_output[minibatchsize-1][1]))\n",
    "        #plt.imshow(random_train_patches[minibatchsize-1][0])\n",
    "        #plt.show()\n",
    "        \n",
    "        # Random validation sample information IMPORTANT: Use the hot encoded labels (that's the way the algorithm works)\n",
    "        random_valid_patches, random_valid_output = sampleBatches(valid_non_vessel_patches, valid_vessel_patches,\n",
    "                                                                  batch_size = minibatchsize, distribution = 0.5)\n",
    "\n",
    "        new_train_loss = train(random_train_patches, random_train_output)\n",
    "        losslist.append(new_train_loss)\n",
    "\n",
    "        new_valid_loss = validate(random_valid_patches, random_valid_output)\n",
    "        validlosslist.append(new_valid_loss)\n",
    "        #select random training en validation samples and perform training and validation steps here.\n",
    "        \n",
    "        \n",
    "        print(\"Currently at batch %d, has loss of %0.2f and validloss of %0.2f \" % (i, new_train_loss, new_valid_loss))\n",
    "        print(test(all_train_patches[98:100]))\n",
    "        \n",
    "        \n",
    "    t1 = time.time()\n",
    "    print 'Training time: {} seconds'.format(t1-t0)\n",
    "    \n",
    "    return losslist, validlosslist\n",
    "\n",
    "\n",
    "# Creates batches of vessel and non vessel images of a certain distribution\n",
    "def sampleBatches(non_vessel_patches, vessel_patches, batch_size = 100, distribution = 0.5):\n",
    "  \n",
    "    if distribution < 0 or distribution > 1:\n",
    "        raise Exception(\"Impossible distribution\")\n",
    "            \n",
    "    # Choose non vessel patches for in the batch\n",
    "    samples_non_vessel = np.arange(len(non_vessel_patches)) #numbers from 0 until the number of samples\n",
    "    random_non_vessel_samples = random.sample(samples_non_vessel, int(batch_size * distribution))\n",
    "    batch_non_vessel_output = int(batch_size * distribution) * [[1, 0]]\n",
    "    batch_non_vessel_patches = np.asarray(non_vessel_patches)[random_non_vessel_samples]\n",
    "    \n",
    "    # Choose vessel patches for in the batch\n",
    "    samples_vessel = np.arange(len(vessel_patches)) #numbers from 0 until the number of samples\n",
    "    random_vessel_samples = random.sample(samples_vessel, int(batch_size * (1 - distribution)))\n",
    "    batch_vessel_output = int(batch_size * (1 - distribution)) * [[0, 1]]\n",
    "    batch_vessel_patches = np.asarray(vessel_patches)[random_vessel_samples]\n",
    "             \n",
    "    # Combine the batches    \n",
    "    batch_patches = np.append(batch_non_vessel_patches, batch_vessel_patches, axis = 0)\n",
    "    batch_output = np.append(batch_non_vessel_output, batch_vessel_output, axis = 0)\n",
    "                                          \n",
    "    return batch_patches, batch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at batch 0, has loss of 0.70 and validloss of 0.70 \n",
      "[[ 0.5604183  0.4395817]\n",
      " [ 0.5604183  0.4395817]]\n",
      "Currently at batch 1, has loss of 0.70 and validloss of 0.70 \n",
      "[[ 0.55880693  0.44119307]\n",
      " [ 0.55880693  0.44119307]]\n",
      "Currently at batch 2, has loss of 0.70 and validloss of 0.70 \n",
      "[[ 0.55653443  0.44346557]\n",
      " [ 0.55653443  0.44346557]]\n",
      "Currently at batch 3, has loss of 0.70 and validloss of 0.70 \n",
      "[[ 0.55369687  0.44630313]\n",
      " [ 0.55369687  0.44630313]]\n",
      "Currently at batch 4, has loss of 0.70 and validloss of 0.70 \n",
      "[[ 0.55038843  0.44961157]\n",
      " [ 0.55038843  0.44961157]]\n",
      "Currently at batch 5, has loss of 0.70 and validloss of 0.70 \n",
      "[[ 0.54670073  0.45329927]\n",
      " [ 0.54670073  0.45329927]]\n",
      "Currently at batch 6, has loss of 0.70 and validloss of 0.70 \n",
      "[[ 0.54272195  0.45727805]\n",
      " [ 0.54272195  0.45727805]]\n",
      "Currently at batch 7, has loss of 0.70 and validloss of 0.70 \n",
      "[[ 0.53853601  0.46146399]\n",
      " [ 0.53853601  0.46146399]]\n",
      "Currently at batch 8, has loss of 0.70 and validloss of 0.70 \n",
      "[[ 0.53422185  0.46577815]\n",
      " [ 0.53422185  0.46577815]]\n",
      "Currently at batch 9, has loss of 0.70 and validloss of 0.69 \n",
      "[[ 0.52985282  0.47014718]\n",
      " [ 0.52985282  0.47014718]]\n",
      "Currently at batch 10, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.52549596  0.47450404]\n",
      " [ 0.52549596  0.47450404]]\n",
      "Currently at batch 11, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.52121191  0.47878809]\n",
      " [ 0.52121191  0.47878809]]\n",
      "Currently at batch 12, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.51705443  0.48294557]\n",
      " [ 0.51705443  0.48294557]]\n",
      "Currently at batch 13, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.51306992  0.48693008]\n",
      " [ 0.51306992  0.48693008]]\n",
      "Currently at batch 14, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.50929807  0.49070193]\n",
      " [ 0.50929807  0.49070193]]\n",
      "Currently at batch 15, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.50577146  0.49422854]\n",
      " [ 0.50577146  0.49422854]]\n",
      "Currently at batch 16, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.50251576  0.49748424]\n",
      " [ 0.50251576  0.49748424]]\n",
      "Currently at batch 17, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.49955049  0.50044951]\n",
      " [ 0.49955049  0.50044951]]\n",
      "Currently at batch 18, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.49688882  0.50311118]\n",
      " [ 0.49688882  0.50311118]]\n",
      "Currently at batch 19, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.49453808  0.50546192]\n",
      " [ 0.49453808  0.50546192]]\n",
      "Currently at batch 20, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.49250046  0.50749954]\n",
      " [ 0.49250046  0.50749954]]\n",
      "Currently at batch 21, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.49077352  0.50922648]\n",
      " [ 0.49077352  0.50922648]]\n",
      "Currently at batch 22, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.48935048  0.51064952]\n",
      " [ 0.48935048  0.51064952]]\n",
      "Currently at batch 23, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.48822112  0.51177888]\n",
      " [ 0.48822112  0.51177888]]\n",
      "Currently at batch 24, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.48737174  0.51262826]\n",
      " [ 0.48737174  0.51262826]]\n",
      "Currently at batch 25, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.48678647  0.51321353]\n",
      " [ 0.48678647  0.51321353]]\n",
      "Currently at batch 26, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.48644711  0.51355289]\n",
      " [ 0.48644711  0.51355289]]\n",
      "Currently at batch 27, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.48633394  0.51366606]\n",
      " [ 0.48633394  0.51366606]]\n",
      "Currently at batch 28, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.48642577  0.51357423]\n",
      " [ 0.48642577  0.51357423]]\n",
      "Currently at batch 29, has loss of 0.69 and validloss of 0.69 \n",
      "[[ 0.4867011  0.5132989]\n",
      " [ 0.4867011  0.5132989]]\n",
      "Training time: 310.524000168 seconds\n"
     ]
    }
   ],
   "source": [
    "minibatches = 30\n",
    "minibatchsize = 1000\n",
    "losslist, validlosslist = training_the_network(all_train_output, valid_output, all_train_patches, valid_patches, minibatches, minibatchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Testing algorithm</h4>\n",
    "Test the algorithm with putting in an image_patch and checking if the result is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3c3dce20e4f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mtesting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image_patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image_patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mtesting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image_patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtest_set_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\s119104\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\s119104\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "test_image_patches = image_patches\n",
    "\n",
    "test_results = []\n",
    "for i in range(nr_images_test):\n",
    "    test_image_predictions = []\n",
    "    for j in range(0,len(test_image_patches[i]), 500):\n",
    "        if j + 500 >= len(test_image_patches[i]):\n",
    "            testing = test(test_image_patches[i][j:j+len(test_image_patches[i])])\n",
    "        else:\n",
    "            testing = test(test_image_patches[i][j:j+500])\n",
    "        \n",
    "        test_set_predictions = np.argmax(testing, axis = 1)\n",
    "        test_image_predictions.extend(test_set_predictions)\n",
    "    \n",
    "    test_results.append(test_image_predictions)\n",
    "    print(\"Currently at image %d\" % i)\n",
    "    print sum(test_image_predictions)/len(test_image_predictions)\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "print 'Testing time: {} seconds'.format(t1-t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights\n"
     ]
    }
   ],
   "source": [
    "def save_weights(filename,network):\n",
    "    with open(filename, 'wb') as f:\n",
    "        cPickle.dump(lasagne.layers.get_all_param_values(network), f)\n",
    "        cPickle.dump(losslist, f)\n",
    "        cPickle.dump(validlosslist, f)\n",
    "        cPickle.dump(test_results, f)\n",
    "        \n",
    "def load_weights(filename, network):\n",
    "    with open(filename, 'rb') as f:\n",
    "        lasagne.layers.set_all_param_values(network, cPickle.load(f))\n",
    "\n",
    "project_path = os.getcwd()\n",
    "filename = project_path + '/Project1_weights.pkl' #'C:/Users/Atte/Desktop/Capita selecta/8DM20-CSMIA-group-3/Project/Project1_weights.pkl' \n",
    "network = outputlayer\n",
    "save_weights(filename, network)\n",
    "print(\"Saved weights\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
