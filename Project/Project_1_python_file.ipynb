{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep learning project 8DM20 CSMIA</h1>\n",
    "\n",
    "<h4>Group members:</h4>\n",
    "Atte Eskelinen - 1224333 <br>\n",
    "Jolien Migchielsen - 0495058 <br>\n",
    "Lieke van den Wildenberg - 0844697 <br>\n",
    "Osman Akdag - 0842508 <br>\n",
    "Tim Beishuizen - 0791613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import all used packages (unused packages are commented out so far)\n",
    "import os\n",
    "from PIL import Image as PIL_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from sklearn.feature_extraction import image as sklearn_image\n",
    "#matplotlib inline\n",
    "#import theano\n",
    "#import lasagne\n",
    "#import time\n",
    "#import random\n",
    "#random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before every thing can be done, at first the data images have to be read and be made in useable data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function that loads the data\n",
    "def loadData(data_set = 'test', image = '1st_manual'):\n",
    "    \n",
    "    # Check for the correct input\n",
    "    if data_set != 'test' and data_set != 'training':\n",
    "        raise Exception('Not the right data_set file')\n",
    "    if image != '1st_manual' and image != '2nd_manual' and image != 'images' and image != 'mask':\n",
    "        raise Exception('Not the right image file')\n",
    "    if data_set == 'training' and image == '2nd_manual':\n",
    "        raise Exception('File not available')\n",
    "    \n",
    "    # Project and image path\n",
    "    project_path = os.getcwd()\n",
    "    images_path = project_path +  '/8DM20_image_dataset/' + data_set + '/' + image + '/'\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    #Open image for image (20 in total for each of them)\n",
    "    for i in range(1, 21):\n",
    "        \n",
    "        # Find correct image number\n",
    "        image_nr = str(i)\n",
    "        if data_set == 'training':\n",
    "            image_nr = str(20 + i)\n",
    "        elif len(image_nr) == 1:\n",
    "            image_nr = '0' + image_nr\n",
    "            \n",
    "        # Specify path for this image\n",
    "        if image == '1st_manual':\n",
    "            image_path = images_path + image_nr + '_manual1.gif'\n",
    "        elif image == '2nd_manual':\n",
    "            image_path = images_path + image_nr + '_manual2.gif'\n",
    "        elif image == 'images':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '.tif'\n",
    "        elif image == 'mask':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '_mask.gif'\n",
    "        \n",
    "        # Open and append the image to the image list\n",
    "        images.append(PIL_image.open(image_path))\n",
    "    \n",
    "    return images\n",
    "\n",
    "#The function that makes matrices from the images\n",
    "def convertImageToMatrix(images):\n",
    "    \n",
    "    image_matrices = []\n",
    "    \n",
    "    for image in images:\n",
    "        image_matrix = np.asarray(image.convert('L'))\n",
    "        image_matrices.append(image_matrix)\n",
    "        \n",
    "    return image_matrices\n",
    "\n",
    "#The function that prepares the image matrices to the data used for machine learning\n",
    "def prepareMachineLearningData(image_matrix, output_matrix, mask_matrix, kernel_size = 25):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrix, np.ndarray) and \n",
    "            isinstance(output_matrix, np.ndarray) and \n",
    "            isinstance(mask_matrix, np.ndarray)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if not (image_matrix.shape == output_matrix.shape == mask_matrix.shape):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    #if np.unique(output_matrix).shape[0] != 3:\n",
    "    #   raise Exception(\"The output matrix does not consist of only 3 values\")\n",
    "    \n",
    "    if np.unique(mask_matrix).shape[0] != 2:\n",
    "        raise Exception(\"The mask matrix does not consist of only 2 values\")\n",
    "        \n",
    "    if kernel_size % 2 != 1:\n",
    "        raise Exception(\"Not emplemented patches with even dimensions, yet\")\n",
    "    \n",
    "    #Creates a matrix with all possible patches\n",
    "    all_image_patches = sklearn_image.extract_patches_2d(image_matrix,(25,25))\n",
    "    \n",
    "    # Creates an array with all output\n",
    "    matrix_reduction = (kernel_size - 1) / 2\n",
    "    reduced_output_matrix = output_matrix[matrix_reduction : - matrix_reduction, matrix_reduction : - matrix_reduction]\n",
    "    complete_output_array = reduced_output_matrix.reshape(-1)\n",
    "\n",
    "    # Creates an array with all mask locations\n",
    "    reduced_mask_matrix = mask_matrix[matrix_reduction : - matrix_reduction, matrix_reduction : - matrix_reduction]\n",
    "    mask_array = reduced_mask_matrix.reshape(-1)\n",
    "    \n",
    "    image_patches = []\n",
    "    output_array = []\n",
    "    \n",
    "    # Reduces the number of patches and output to only the mask values\n",
    "    for i in range(len(mask_array)):\n",
    "        if mask_array[i] != 0:\n",
    "            image_patches.append(all_image_patches[i,:,:])\n",
    "            output_array.append(complete_output_array[i])\n",
    "    \n",
    "    # Return the image patches and the output array\n",
    "    return image_patches, output_array\n",
    "\n",
    "# Prepare multiple images at once\n",
    "def prepareMultipleImages(image_matrices, output_matrices, mask_matrices, kernel_size = 25):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrices, list) and \n",
    "            isinstance(output_matrices, list) and \n",
    "            isinstance(mask_matrices, list)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if not (len(image_matrices) == len(output_matrices) == len(mask_matrices)):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    if kernel_size % 2 != 1:\n",
    "        raise Exception(\"Not emplemented patches with even dimensions, yet\")\n",
    "    \n",
    "    image_patches = [] \n",
    "    output_arrays = []\n",
    "    \n",
    "    # Finds the output data per image\n",
    "    for i in range(len(image_matrices)):\n",
    "        new_image_patches, new_output_array = prepareMachineLearningData(image_matrices[i], output_matrices[i], \n",
    "                                                                         mask_matrices[i], kernel_size = kernel_size)\n",
    "        image_patches.append(new_image_patches)\n",
    "        output_arrays.append(new_output_array)\n",
    "        \n",
    "        #Print progress for showing time consumption\n",
    "        print\"Progress: {} %\".format(100*(i+1)/len(image_matrices)),\n",
    "              \n",
    "    return image_patches, output_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are loaded and immediately made into matrices for further computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All test image lists\n",
    "test_manual1_images = loadData('test', '1st_manual')\n",
    "test_manual2_images = loadData('test', '2nd_manual')\n",
    "test_raw_images = loadData('test', 'images')\n",
    "test_mask_images = loadData('test', 'mask')\n",
    "\n",
    "# Making matrices of the test images to work with\n",
    "test_manual1_matrices = convertImageToMatrix(test_manual1_images)\n",
    "test_manual2_matrices = convertImageToMatrix(test_manual2_images)\n",
    "test_raw_matrices = convertImageToMatrix(test_raw_images)\n",
    "test_mask_matrices = convertImageToMatrix(test_mask_images)\n",
    "\n",
    "# All training image lists\n",
    "training_manual1_images = loadData('training', '1st_manual')\n",
    "training_raw_images = loadData('training', 'images')\n",
    "training_mask_images = loadData('training', 'mask')\n",
    "\n",
    "# Making matrices of the training images to work with\n",
    "training_manual1_matrices = convertImageToMatrix(training_manual1_images)\n",
    "training_raw_matrices = convertImageToMatrix(training_raw_images)\n",
    "training_mask_matrices = convertImageToMatrix(training_mask_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrices are then used for further preprocessing to retrieve the suitable data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 50 % Progress: 100 %\n"
     ]
    }
   ],
   "source": [
    "#Choose the number of images\n",
    "nr_images = 2\n",
    "\n",
    "# Prepares the data for machine learning: X = image_patches, y = output_array\n",
    "# Both are a list with the patches and output_arrays for multiple images (the number chosen before)\n",
    "image_patches, output_array = prepareMultipleImages(test_raw_matrices[0:nr_images], test_manual1_matrices[0:nr_images], \n",
    "                                                     test_mask_matrices[0:nr_images], 25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is just to show how the data set is built up. There are patches of 25x 25. These values either correspond to a vene pixel or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFAQCgIJAAFAQCACK/wOcNzijBXd/2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17ef3630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be vene pixel?255 (255 is yes, 0 is no)\n"
     ]
    }
   ],
   "source": [
    "image_number = 1\n",
    "pixel = 44 #35645\n",
    "\n",
    "plt.matshow(image_patches[image_number][pixel])\n",
    "plt.show()\n",
    "\n",
    "print(\"Should be vene pixel?\" + str(output_array[image_number][pixel]) + \" (255 is yes, 0 is no)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
