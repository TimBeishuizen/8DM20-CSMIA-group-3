{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep learning project 8DM20 CSMIA</h1>\n",
    "\n",
    "<h4>Group members:</h4>\n",
    "O. Akdag - 0842508 <br>\n",
    "T.P.A. Beishuizen - 0791613 <br>\n",
    "A.S.A. Eskelinen - 1224333 <br>\n",
    "J.H.A. Migchielsen - 0495058 <br>\n",
    "L. van den Wildenberg - 0844697 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import all used packages (unused packages are commented out so far)\n",
    "import os\n",
    "from PIL import Image as PIL_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from sklearn.feature_extraction import image as sklearn_image\n",
    "#matplotlib inline\n",
    "#import theano\n",
    "#import lasagne\n",
    "#import time\n",
    "#import random\n",
    "#random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before every thing can be done, at first the data images have to be read and be made in useable data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function that loads the data\n",
    "def loadData(data_set = 'test', image = '1st_manual'):\n",
    "    \n",
    "    # Check for the correct input\n",
    "    if data_set != 'test' and data_set != 'training':\n",
    "        raise Exception('Not the right data_set file')\n",
    "    if image != '1st_manual' and image != '2nd_manual' and image != 'images' and image != 'mask':\n",
    "        raise Exception('Not the right image file')\n",
    "    if data_set == 'training' and image == '2nd_manual':\n",
    "        raise Exception('File not available')\n",
    "    \n",
    "    # Project and image path\n",
    "    project_path = os.getcwd()\n",
    "    images_path = project_path +  '/8DM20_image_dataset/' + data_set + '/' + image + '/'\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    #Open image for image (20 in total for each of them)\n",
    "    for i in range(1, 21):\n",
    "        \n",
    "        # Find correct image number\n",
    "        image_nr = str(i)\n",
    "        if data_set == 'training':\n",
    "            image_nr = str(20 + i)\n",
    "        elif len(image_nr) == 1:\n",
    "            image_nr = '0' + image_nr\n",
    "            \n",
    "        # Specify path for this image\n",
    "        if image == '1st_manual':\n",
    "            image_path = images_path + image_nr + '_manual1.gif'\n",
    "        elif image == '2nd_manual':\n",
    "            image_path = images_path + image_nr + '_manual2.gif'\n",
    "        elif image == 'images':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '.tif'\n",
    "        elif image == 'mask':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '_mask.gif'\n",
    "        \n",
    "        # Open and append the image to the image list\n",
    "        images.append(PIL_image.open(image_path))\n",
    "        \n",
    "    return images\n",
    "\n",
    "#The function that converts the channels in the images from RGB to gray\n",
    "#and makes matrices from the images\n",
    "def convertImageToMatrix(images):\n",
    "    \n",
    "    image_matrices = []\n",
    "    \n",
    "    for image in images:\n",
    "        image_matrix = np.asarray(image.convert('L'))\n",
    "        image_matrices.append(image_matrix)\n",
    "        \n",
    "    return image_matrices\n",
    "\n",
    "#The function that prepares the image matrices to the data used for machine learning\n",
    "def prepareMachineLearningData(image_matrix, output_matrix, mask_matrix, kernel_size = 25):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrix, np.ndarray) and \n",
    "            isinstance(output_matrix, np.ndarray) and \n",
    "            isinstance(mask_matrix, np.ndarray)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if not (image_matrix.shape == output_matrix.shape == mask_matrix.shape):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    #if np.unique(output_matrix).shape[0] != 3:\n",
    "    #   raise Exception(\"The output matrix does not consist of only 3 values\")\n",
    "    \n",
    "    if np.unique(mask_matrix).shape[0] != 2:\n",
    "        raise Exception(\"The mask matrix does not consist of only 2 values\")\n",
    "        \n",
    "    if kernel_size % 2 != 1:\n",
    "        raise Exception(\"Not emplemented patches with even dimensions, yet\")\n",
    "    \n",
    "    #Creates a matrix with all possible patches\n",
    "    all_image_patches = sklearn_image.extract_patches_2d(image_matrix,(kernel_size,kernel_size))\n",
    "    \n",
    "    # Creates an array with all output\n",
    "    matrix_reduction = (kernel_size - 1) / 2\n",
    "    reduced_output_matrix = output_matrix[matrix_reduction : - matrix_reduction, matrix_reduction : - matrix_reduction]\n",
    "    complete_output_array = reduced_output_matrix.reshape(-1)\n",
    "\n",
    "    # Creates an array with all mask locations\n",
    "    reduced_mask_matrix = mask_matrix[matrix_reduction : - matrix_reduction, matrix_reduction : - matrix_reduction]\n",
    "    mask_array = reduced_mask_matrix.reshape(-1)\n",
    "    \n",
    "    image_patches = []\n",
    "    output_array = []\n",
    "    \n",
    "    # Reduces the number of patches and output to only the mask values\n",
    "    for i in range(len(mask_array)):\n",
    "        if mask_array[i] != 0:\n",
    "            image_patches.append(all_image_patches[i,:,:])\n",
    "            output_array.append(complete_output_array[i])\n",
    "\n",
    "    # Return the image patches and the output array\n",
    "    return image_patches, output_array\n",
    "\n",
    "# Prepare multiple images at once\n",
    "def prepareMultipleImages(image_matrices, output_matrices, mask_matrices, kernel_size = 25):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrices, list) and \n",
    "            isinstance(output_matrices, list) and \n",
    "            isinstance(mask_matrices, list)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if not (len(image_matrices) == len(output_matrices) == len(mask_matrices)):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    if kernel_size % 2 != 1:\n",
    "        raise Exception(\"Not emplemented patches with even dimensions, yet\")\n",
    "    \n",
    "    image_patches = [] \n",
    "    output_arrays = []\n",
    "    \n",
    "    # Finds the output data per image\n",
    "    for i in range(len(image_matrices)):\n",
    "        new_image_patches, new_output_array = prepareMachineLearningData(image_matrices[i], output_matrices[i], \n",
    "                                                                         mask_matrices[i], kernel_size = kernel_size)\n",
    "        image_patches.append(new_image_patches)\n",
    "        output_arrays.append(new_output_array)\n",
    "        \n",
    "        #Print progress for showing time consumption\n",
    "        print\"Progress: {} %\".format(100*(i+1)/len(image_matrices)),\n",
    "              \n",
    "    return image_patches, output_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are loaded and immediately made into matrices for further computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All test image lists\n",
    "test_manual1_images = loadData('test', '1st_manual')\n",
    "test_manual2_images = loadData('test', '2nd_manual')\n",
    "test_raw_images = loadData('test', 'images')\n",
    "test_mask_images = loadData('test', 'mask')\n",
    "\n",
    "# Making matrices of the test images to work with\n",
    "test_manual1_matrices = convertImageToMatrix(test_manual1_images)\n",
    "test_manual2_matrices = convertImageToMatrix(test_manual2_images)\n",
    "test_raw_matrices = convertImageToMatrix(test_raw_images)\n",
    "test_mask_matrices = convertImageToMatrix(test_mask_images)\n",
    "\n",
    "# All training image lists\n",
    "training_manual1_images = loadData('training', '1st_manual')\n",
    "training_raw_images = loadData('training', 'images')\n",
    "training_mask_images = loadData('training', 'mask')\n",
    "\n",
    "# Making matrices of the training images to work with\n",
    "training_manual1_matrices = convertImageToMatrix(training_manual1_images)\n",
    "training_raw_matrices = convertImageToMatrix(training_raw_images)\n",
    "training_mask_matrices = convertImageToMatrix(training_mask_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrices are then used for further preprocessing to retrieve the suitable data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 50 % Progress: 100 %\n"
     ]
    }
   ],
   "source": [
    "#Choose the number of images\n",
    "nr_images = 2\n",
    "\n",
    "# Prepares the data for machine learning: X = image_patches, y = output_array\n",
    "# Both are a list with the patches and output_arrays for multiple images (the number chosen before)\n",
    "image_patches, output_array = prepareMultipleImages(test_raw_matrices[0:nr_images], test_manual1_matrices[0:nr_images], \n",
    "                                                     test_mask_matrices[0:nr_images], 25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is just to show how the data set is built up. There are patches of 25x 25. These values either correspond to a vene pixel or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICEQACQEAoCEQACQ/D9L0bLHV6vJfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115cbdbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be vene pixel? 0 (255 is yes, 0 is no)\n"
     ]
    }
   ],
   "source": [
    "image_number = 1\n",
    "pixel = 35620 #35645\n",
    "\n",
    "plt.matshow(image_patches[image_number][pixel])\n",
    "plt.show()\n",
    "\n",
    "print(\"Should be vene pixel? \" + str(output_array[image_number][pixel]) + \" (255 is yes, 0 is no)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
