{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep learning project 8DM20 CSMIA</h1>\n",
    "\n",
    "<h4>Group members:</h4>\n",
    "O. Akdag - 0842508 <br>\n",
    "T.P.A. Beishuizen - 0791613 <br>\n",
    "A.S.A. Eskelinen - 1224333 <br>\n",
    "J.H.A. Migchielsen - 0495058 <br>\n",
    "L. van den Wildenberg - 0844697 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import all used packages (unused packages are commented out so far)\n",
    "import os\n",
    "from PIL import Image as PIL_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from sklearn.feature_extraction import image as sklearn_image\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "#matplotlib inline\n",
    "import theano\n",
    "import lasagne\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import cPickle\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Preprocessing</h4>\n",
    "\n",
    "Before every thing can be done, at first the data images have to be read and be made in useable data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function that loads the data\n",
    "def loadData(data_set = 'test', image = '1st_manual'):\n",
    "    \n",
    "    # Check for the correct input\n",
    "    if data_set != 'test' and data_set != 'training':\n",
    "        raise Exception('Not the right data_set file')\n",
    "    if image != '1st_manual' and image != '2nd_manual' and image != 'images' and image != 'mask':\n",
    "        raise Exception('Not the right image file')\n",
    "    if data_set == 'training' and image == '2nd_manual':\n",
    "        raise Exception('File not available')\n",
    "    \n",
    "    # Project and image path\n",
    "    project_path = os.getcwd()\n",
    "    images_path = project_path +  '/8DM20_image_dataset/' + data_set + '/' + image + '/'\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    #Open image for image (20 in total for each of them)\n",
    "    for i in range(1, 21):\n",
    "        \n",
    "        # Find correct image number\n",
    "        image_nr = str(i)\n",
    "        if data_set == 'training':\n",
    "            image_nr = str(20 + i)\n",
    "        elif len(image_nr) == 1:\n",
    "            image_nr = '0' + image_nr\n",
    "            \n",
    "        # Specify path for this image\n",
    "        if image == '1st_manual':\n",
    "            image_path = images_path + image_nr + '_manual1.gif'\n",
    "        elif image == '2nd_manual':\n",
    "            image_path = images_path + image_nr + '_manual2.gif'\n",
    "        elif image == 'images':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '.tif'\n",
    "        elif image == 'mask':\n",
    "            image_path = images_path + image_nr + '_' + data_set + '_mask.gif'\n",
    "        \n",
    "        # Open and append the image to the image list\n",
    "        images.append(PIL_image.open(image_path))\n",
    "        \n",
    "    return images\n",
    "\n",
    "#The function that converts the channels in the images from RGB to gray\n",
    "#and makes matrices from the images\n",
    "def convertImageToMatrix(images):\n",
    "    \n",
    "    image_matrices = []\n",
    "    \n",
    "    for image in images:\n",
    "        image_matrix = np.asarray(image.convert('RGB'))\n",
    "        green_image_matrix = image_matrix[:,:,1]\n",
    "        image_matrices.append(green_image_matrix)\n",
    "        \n",
    "    return image_matrices\n",
    "\n",
    "#The function that prepares the image matrices to the data used for machine learning\n",
    "def prepareMachineLearningData(image_matrix, output_matrix, mask_matrix, kernel_size, mask_removal = 'pixel'):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrix, np.ndarray) and \n",
    "            isinstance(output_matrix, np.ndarray) and \n",
    "            isinstance(mask_matrix, np.ndarray)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if mask_removal != 'pixel' and mask_removal != 'patch':\n",
    "        raise Exception(\"Unknown mask data removal type\")\n",
    "    \n",
    "    if not (image_matrix.shape == output_matrix.shape == mask_matrix.shape):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    if np.unique(mask_matrix).shape[0] != 2:\n",
    "        raise Exception(\"The mask matrix does not consist of only 2 values\")\n",
    "    \n",
    "    #image_patches = []\n",
    "    #output_array = []\n",
    "    \n",
    "    #for i in range(image_matrix.shape[0]):\n",
    "    #    for j in range(image_matrix.shape[0]):\n",
    "    #        if mask_matrix[i,j] == 255 and i >= kernel_size/2 + 1 and i <= image_matrix.shape[0] - kernel_size / 2 - 1 and j >= kernel_size/2 + 1 and j <= image_matrix.shape[1] - kernel_size / 2 - 1:\n",
    "    #            if  not (0 in mask_matrix[i - kernel_size/2 + 1: i + kernel_size / 2 + 1, \n",
    "    #                                              j - kernel_size/2 + 1: j + kernel_size / 2 + 1]):             \n",
    "    #                image_patches.append(image_matrix[i - kernel_size/2 + 1: i + kernel_size / 2 + 1, \n",
    "    #                                              j - kernel_size/2 + 1: j + kernel_size / 2 + 1])\n",
    "    #                output_array.append(output_matrix[i,j])\n",
    "\n",
    "    #image_patches = np.expand_dims(image_patches, axis = 1)\n",
    "    \n",
    "        #Creates a matrix with all possible patches\n",
    "    all_image_patches = sklearn_image.extract_patches_2d(image_matrix,(kernel_size,kernel_size))\n",
    "    all_image_patches = np.expand_dims(all_image_patches, axis=1)\n",
    "    \n",
    "    if kernel_size % 2 != 0:\n",
    "         # Creates an array with all output\n",
    "        mat_red = (kernel_size - 1) / 2\n",
    "        reduced_output_matrix = output_matrix[ mat_red : -  mat_red,  mat_red : -  mat_red]\n",
    "        complete_output_array = reduced_output_matrix.reshape(-1)\n",
    "\n",
    "        new_mask_matrix = mask_matrix.copy()\n",
    "        \n",
    "        # Makes some additional mask values zero on the edge of the mask\n",
    "        if mask_removal == 'patch':\n",
    "            for i in range(mat_red, mask_matrix.shape[0] -  mat_red + 1):\n",
    "                for j in range(mat_red, mask_matrix.shape[1] -  mat_red + 1):\n",
    "                    if 0 in mask_matrix[i - mat_red : i + mat_red + 1, j - mat_red: j + mat_red + 1]:\n",
    "                        new_mask_matrix[i,j] = 0;\n",
    "        \n",
    "        # Creates an array with all mask locations\n",
    "        reduced_mask_matrix = new_mask_matrix[ mat_red : -  mat_red, mat_red : -  mat_red]\n",
    "        mask_array = reduced_mask_matrix.reshape(-1)\n",
    "    \n",
    "    else:\n",
    "        # Creates an array with all output\n",
    "        mat_red = (kernel_size) / 2\n",
    "        reduced_output_matrix = output_matrix[mat_red - 1: -  mat_red,  mat_red - 1: -  mat_red]\n",
    "        complete_output_array = reduced_output_matrix.reshape(-1)\n",
    "\n",
    "        new_mask_matrix = mask_matrix.copy()\n",
    "        \n",
    "        # Makes some additional mask values zero on the edge of the mask\n",
    "        if mask_removal == 'patch':\n",
    "            for i in range(mat_red - 1, mask_matrix.shape[0] -  mat_red + 1):\n",
    "                for j in range(mat_red - 1, mask_matrix.shape[1] -  mat_red + 1):\n",
    "                    if 0 in mask_matrix[i - mat_red + 1 : i + mat_red + 1, j - mat_red + 1: j + mat_red + 1]:\n",
    "                        new_mask_matrix[i,j] = 0;\n",
    "                     \n",
    "        # Creates an array with all mask locations\n",
    "        reduced_mask_matrix = new_mask_matrix[mat_red - 1: - mat_red, mat_red - 1: - mat_red]\n",
    "        mask_array = reduced_mask_matrix.reshape(-1) \n",
    "\n",
    "    image_patches = []\n",
    "    output_array = []\n",
    "    \n",
    "    # Reduces the number of patches and output to only the mask values\n",
    "    for i in range(len(mask_array)):\n",
    "        if mask_array[i] != 0:\n",
    "            image_patches.append(all_image_patches[i,:,:])\n",
    "            output_array.append(complete_output_array[i])\n",
    "        \n",
    "    \n",
    "    # Return the image patches and the output array\n",
    "    return image_patches, output_array\n",
    "\n",
    "# Prepare multiple images at once\n",
    "def prepareMultipleImages(image_matrices, output_matrices, mask_matrices, kernel_size = 25, mask_removal = 'pixel'):\n",
    "    #Check if correct input\n",
    "    if not (isinstance(image_matrices, list) and \n",
    "            isinstance(output_matrices, list) and \n",
    "            isinstance(mask_matrices, list)):\n",
    "        raise Exception(\"Not all input matrices are numpy matrices\")\n",
    "    \n",
    "    if not (len(image_matrices) == len(output_matrices) == len(mask_matrices)):\n",
    "        raise Exception(\"The images are not the same size\")\n",
    "    \n",
    "    image_patches = [] \n",
    "    output_arrays = []\n",
    "    \n",
    "    # Finds the output data per image\n",
    "    for i in range(len(image_matrices)):\n",
    "        new_image_patches, new_output_array = prepareMachineLearningData(image_matrices[i], output_matrices[i], mask_matrices[i], \n",
    "                                                                         kernel_size = kernel_size, mask_removal = mask_removal)\n",
    "        image_patches.append(new_image_patches)\n",
    "        output_arrays.append(new_output_array)\n",
    "        \n",
    "        #Print progress for showing time consumption\n",
    "        print\"Progress: {} %\".format(100*(i+1)/len(image_matrices)),\n",
    "              \n",
    "    return image_patches, output_arrays\n",
    "\n",
    "def createVesselImage(output_array, mask_matrix, kernel_size, mask_removal = \"pixel\"):\n",
    "    #Check if input is correct\n",
    "    if not isinstance(output_array, list) or not isinstance(mask_matrix, np.ndarray) or not isinstance(kernel_size, int):\n",
    "        raise Exception(\"Not the right input variables\")\n",
    "    \n",
    "    if mask_removal != \"pixel\" and mask_removal != 'patch':\n",
    "        raise Exception(\"Unknown mask removal type\")\n",
    "    \n",
    "    #Create an output_matrix for the output array\n",
    "    #output_matrix = np.array(mask_matrix)\n",
    "    output_matrix = np.zeros(mask_matrix.shape)\n",
    "    output_loc = 0\n",
    "    \n",
    "    # Take into account that mask pixels too close to the border are lost due to inability to make patches\n",
    "    edge_corr = int(math.ceil(kernel_size / 2) - 1)\n",
    "    \n",
    "    new_mask_matrix = mask_matrix.copy()\n",
    "    \n",
    "    # Makes some additional mask values zero on the edge of the mask\n",
    "    if mask_removal == 'patch':\n",
    "        for i in range(edge_corr, mask_matrix.shape[0] - edge_corr - 2):\n",
    "            for j in range(edge_corr, mask_matrix.shape[1] - edge_corr - 2):\n",
    "                if 0 in mask_matrix[i - edge_corr  : i + edge_corr + 2, j - edge_corr: j + edge_corr + 2]:\n",
    "                    new_mask_matrix[i,j] = 0;\n",
    "       \n",
    "    # Check every pixel within the mask for a vessel pixel\n",
    "    for i in range(mask_matrix.shape[0] - kernel_size + 1):\n",
    "        for j in range(mask_matrix.shape[1] - kernel_size + 1):\n",
    "            if new_mask_matrix[i + edge_corr, j + edge_corr] == 255:\n",
    "                output_matrix[i + edge_corr, j + edge_corr] = output_array[output_loc]\n",
    "                output_loc += 1\n",
    "                \n",
    "    return output_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are loaded and immediately made into matrices for further computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All test image lists\n",
    "test_manual1_images = loadData('test', '1st_manual')\n",
    "test_manual2_images = loadData('test', '2nd_manual')\n",
    "test_raw_images = loadData('test', 'images')\n",
    "test_mask_images = loadData('test', 'mask')\n",
    "\n",
    "# Making matrices of the test images to work with\n",
    "test_manual1_matrices = convertImageToMatrix(test_manual1_images)\n",
    "test_manual2_matrices = convertImageToMatrix(test_manual2_images)\n",
    "test_raw_matrices = convertImageToMatrix(test_raw_images)\n",
    "test_mask_matrices = convertImageToMatrix(test_mask_images)\n",
    "\n",
    "# All training image lists\n",
    "training_manual1_images = loadData('training', '1st_manual')\n",
    "training_raw_images = loadData('training', 'images')\n",
    "training_mask_images = loadData('training', 'mask')\n",
    "\n",
    "# Making matrices of the training images to work with\n",
    "training_manual1_matrices = convertImageToMatrix(training_manual1_images)\n",
    "training_raw_matrices = convertImageToMatrix(training_raw_images)\n",
    "training_mask_matrices = convertImageToMatrix(training_mask_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrices are then used for further preprocessing to retrieve the suitable data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 50 % Progress: 100 % Progress: 50 % Progress: 100 %\n"
     ]
    }
   ],
   "source": [
    "#Choose the number of images\n",
    "nr_images_training = 2\n",
    "nr_images_test = 2\n",
    "\n",
    "# Prepares the data for machine learning: X = image_patches, y = output_array\n",
    "# Both are a list with the patches and output_arrays for multiple images (the number chosen before)\n",
    "image_patches, output_array = prepareMultipleImages(training_raw_matrices[0:nr_images_training], training_manual1_matrices[0:nr_images_training], \n",
    "                                                     training_mask_matrices[0:nr_images_training], 32, mask_removal = 'patch')\n",
    "test_image_patches, test_output_array = prepareMultipleImages(test_raw_matrices[0:nr_images_test], test_manual1_matrices[0:nr_images_test], \n",
    "                                                     test_mask_matrices[0:nr_images_test], 32, mask_removal = 'patch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Algorithm setup</h4>\n",
    "The following algorithms are to show how the data set is built up. There are patches of 32x 32. These values either correspond to a vene pixel or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_validation_set(image_patches, output_array):\n",
    "    all_train_patches = []\n",
    "    all_train_output = []\n",
    "    \n",
    "    # Make an array with the patches and the last one is the validation image\n",
    "    for i in range(nr_images_training - 1):\n",
    "        for j in range(len(image_patches[i])):\n",
    "            all_train_patches.append(image_patches[i][j])\n",
    "            all_train_output.append(output_array[i][j])\n",
    "\n",
    "    valid_patches = image_patches[nr_images_training - 1]\n",
    "    valid_output = output_array[nr_images_training - 1]\n",
    "    \n",
    "    return all_train_patches, all_train_output, valid_patches, valid_output\n",
    "\n",
    "def hot_encoding(all_train_output, valid_output):\n",
    "    train_hot_output = np.zeros((len(all_train_output),2),dtype=np.int16)\n",
    "\n",
    "    # Make hot encoding training set\n",
    "    for i in range(len(train_hot_output)):\n",
    "        if all_train_output[i] == 0:\n",
    "            train_hot_output[i,0] = 1\n",
    "        else:\n",
    "            train_hot_output[i,1] = 1      \n",
    "\n",
    "    # Make hot encoding validation set\n",
    "    valid_hot_output = np.zeros((len(valid_output),2),dtype=np.int16)\n",
    "\n",
    "    for i in range(len(valid_hot_output)):\n",
    "        if valid_output[i] == 0:\n",
    "            valid_hot_output[i,0] = 1\n",
    "        else:\n",
    "            valid_hot_output[i,1] = 1\n",
    "    \n",
    "    return train_hot_output, valid_hot_output\n",
    "\n",
    "\n",
    "#def test_set(test_image_patches, test_output_array):\n",
    "#    all_test_patches = []\n",
    "#    all_test_output_array = []\n",
    "#    \n",
    "#    for i in range(nr_images_test):\n",
    "#        for j in range(len(test_image_patches[i])):\n",
    "#            all_test_patches.append(test_image_patches[i][j])\n",
    "#            all_test_output_array.append(test_output_array[i][j])\n",
    "#                \n",
    "#    return all_test_patches, all_test_output_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to first make the output array. This is done with hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_train_patches, all_train_output, valid_patches, valid_output = train_and_validation_set(image_patches, output_array)\n",
    "train_hot_output, valid_hot_output = hot_encoding(all_train_output, valid_output)\n",
    "\n",
    "#all_test_patches, all_test_output_array = test_set(test_image_patches, test_output_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the LeNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildLeNet(X1):\n",
    "    inputlayer = lasagne.layers.InputLayer(shape=(None, 1, 32, 32),input_var=X1)    \n",
    "    print inputlayer.output_shape\n",
    "    \n",
    "    layer1 = lasagne.layers.Conv2DLayer(inputlayer, num_filters=6, filter_size=(5,5), nonlinearity=lasagne.nonlinearities.rectify, W=lasagne.init.GlorotUniform())\n",
    "    print layer1.output_shape \n",
    "    \n",
    "    layer2 = lasagne.layers.MaxPool2DLayer(layer1, pool_size=(2, 2))\n",
    "    print layer2.output_shape \n",
    "    \n",
    "    layer3 = lasagne.layers.Conv2DLayer(layer2, num_filters=16, filter_size=(5,5), nonlinearity=lasagne.nonlinearities.rectify, W=lasagne.init.GlorotUniform())\n",
    "    print layer3.output_shape \n",
    "    \n",
    "    layer4 = lasagne.layers.MaxPool2DLayer(layer3, pool_size=(2, 2))\n",
    "    print layer4.output_shape \n",
    "    \n",
    "    layer4 = lasagne.layers.flatten(layer4)\n",
    "    print layer4.output_shape \n",
    "    \n",
    "    layer5 = lasagne.layers.DenseLayer(layer4,num_units=120,nonlinearity=lasagne.nonlinearities.rectify)    \n",
    "    print layer5.output_shape \n",
    "    \n",
    "    layer6 = lasagne.layers.DenseLayer(layer5,num_units=84,nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    print layer6.output_shape \n",
    "    \n",
    "    outputlayer = lasagne.layers.DenseLayer(layer6,num_units=2,nonlinearity=lasagne.nonlinearities.softmax)     \n",
    "    print outputlayer.output_shape \n",
    "    \n",
    "    return layer1, layer2, layer3, layer4, layer5, layer6, outputlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 32, 32)\n",
      "(None, 6, 28, 28)\n",
      "(None, 6, 14, 14)\n",
      "(None, 16, 10, 10)\n",
      "(None, 16, 5, 5)\n",
      "(None, 400)\n",
      "(None, 120)\n",
      "(None, 84)\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "X = theano.tensor.tensor4()\n",
    "Y = theano.tensor.matrix()\n",
    "layer1, layer2, layer3, layer4, layer5, layer6, outputlayer = buildLeNet(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions for training, validation and testing purposes for the previously made LeNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputtrain = lasagne.layers.get_output(outputlayer) #function that gets the output from the network defined before.\n",
    "trainloss = lasagne.objectives.categorical_crossentropy(outputtrain, Y).mean() #function that computes the mean crossentropy between the output and the real labels.\n",
    "params = lasagne.layers.get_all_params(outputlayer, trainable=True) #function that gets all the parameters (weights) in the network.\n",
    "updates = lasagne.updates.momentum(trainloss, params, learning_rate=0.001) #function that performs an update of the weights based on the loss.\n",
    "train = theano.function(inputs=[X, Y], outputs=trainloss, updates=updates, allow_input_downcast=True) #function that does all the above based on training samples X and real labels Y.\n",
    "\n",
    "validate = theano.function(inputs=[X, Y], outputs=trainloss, allow_input_downcast=True) #function that computes the loss without performing an update\n",
    "\n",
    "outputtest = lasagne.layers.get_output(outputlayer, deterministic=True) #function that gets the output from the network defined before.\n",
    "test = theano.function(inputs=[X], outputs=outputtest, allow_input_downcast=True) #function that gets the output based on input X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def training_the_network(all_train_output, valid_output, all_train_patches, valid_patches, minibatches = 250, minibatchsize = 100):\n",
    "\n",
    "    trainingsamples = np.arange(len(all_train_output)) #numbers from 0 until the number of samples\n",
    "    validsamples = np.arange(len(valid_output))\n",
    "\n",
    "    losslist = []\n",
    "    validlosslist = []\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_non_vessel_patches = []\n",
    "    train_vessel_patches = []\n",
    "    \n",
    "    #First create two training lists. One with vessel patches and one without\n",
    "    for i in range(len(all_train_output)):\n",
    "        if all_train_output[i] == 0:\n",
    "            train_non_vessel_patches.append(all_train_patches[i])          \n",
    "        else:\n",
    "            train_vessel_patches.append(all_train_patches[i])\n",
    "    \n",
    "    valid_non_vessel_patches = []\n",
    "    valid_vessel_patches = []\n",
    "    \n",
    "    #Second create two valid lists. One with vessel patches and one without\n",
    "    for i in range(len(valid_output)):\n",
    "        if valid_output[i] == 0:\n",
    "            valid_non_vessel_patches.append(valid_patches[i])          \n",
    "        else:\n",
    "            valid_vessel_patches.append(valid_patches[i])\n",
    "    \n",
    "    for i in xrange(minibatches):\n",
    "\n",
    "        # Random train sample information. IMPORTANT: Use the hot encoded labels (that's the way the algorithm works)\n",
    "        random_train_patches, random_train_output = sampleBatches(train_non_vessel_patches, train_vessel_patches, \n",
    "                                                                  batch_size = minibatchsize, distribution = 0.5)\n",
    "\n",
    "        # Random validation sample information IMPORTANT: Use the hot encoded labels (that's the way the algorithm works)\n",
    "        random_valid_patches, random_valid_output = sampleBatches(valid_non_vessel_patches, valid_vessel_patches,\n",
    "                                                                  batch_size = minibatchsize, distribution = 0.5)\n",
    "\n",
    "        new_train_loss = train(random_train_patches, random_train_output)\n",
    "        losslist.append(new_train_loss)\n",
    "\n",
    "        new_valid_loss = validate(random_valid_patches, random_valid_output)\n",
    "        validlosslist.append(new_valid_loss)\n",
    "        #select random training en validation samples and perform training and validation steps here.\n",
    "\n",
    "        print(\"Currently at batch %d , has loss of %0.2f and validloss of %0.2f \" % (i, new_train_loss, new_valid_loss))\n",
    "        \n",
    "    t1 = time.time()\n",
    "    print 'Training time: {} seconds'.format(t1-t0)\n",
    "    \n",
    "    return losslist, validlosslist\n",
    "\n",
    "\n",
    "# Creates batches of vessel and non vessel images of a certain distribution\n",
    "def sampleBatches(non_vessel_patches, vessel_patches, batch_size = 100, distribution = 0.5):\n",
    "  \n",
    "    if distribution < 0 or distribution > 1:\n",
    "        raise Exception(\"Impossible distribution\")\n",
    "            \n",
    "    # Choose non vessel patches for in the batch\n",
    "    samples_non_vessel = np.arange(len(non_vessel_patches)) #numbers from 0 until the number of samples\n",
    "    random_non_vessel_samples = random.sample(samples_non_vessel, int(batch_size * distribution))\n",
    "    batch_non_vessel_output = int(batch_size * distribution) * [[1, 0]]\n",
    "    batch_non_vessel_patches = np.asarray(non_vessel_patches)[random_non_vessel_samples]\n",
    "    \n",
    "    # Choose vessel patches for in the batch\n",
    "    samples_vessel = np.arange(len(vessel_patches)) #numbers from 0 until the number of samples\n",
    "    random_vessel_samples = random.sample(samples_vessel, int(batch_size * (1 - distribution)))\n",
    "    batch_vessel_output = int(batch_size * (1 - distribution)) * [[0, 1]]\n",
    "    batch_vessel_patches = np.asarray(vessel_patches)[random_vessel_samples]\n",
    "             \n",
    "    # Combine the batches    \n",
    "    batch_patches = np.append(batch_non_vessel_patches, batch_vessel_patches, axis = 0)\n",
    "    batch_output = np.append(batch_non_vessel_output, batch_vessel_output, axis = 0)\n",
    "                                          \n",
    "    return batch_patches, batch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at batch 0 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 1 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 2 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 3 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 4 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 5 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 6 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 7 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 8 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 9 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 10 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 11 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 12 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 13 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 14 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 15 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 16 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 17 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 18 , has loss of 0.69 and validloss of 0.69 \n",
      "Currently at batch 19 , has loss of 0.69 and validloss of 0.69 \n",
      "Training time: 44.5099999905 seconds\n"
     ]
    }
   ],
   "source": [
    "minibatches = 20\n",
    "minibatchsize = 200\n",
    "losslist, validlosslist = training_the_network(all_train_output, valid_output, all_train_patches, valid_patches, minibatches, minibatchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4abbd080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure()\n",
    "#plt.plot(losslist[2:])\n",
    "#plt.plot(validlosslist[2:])\n",
    "#plt.legend(['Training loss','Validation loss'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7db282278b59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mtesting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image_patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image_patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mtesting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image_patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtest_set_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\s119104\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\s119104\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\s119104\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\tensor\\blas.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out)\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[1;31m# The error raised by numpy has no shape information, we mean to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "test_image_patches = image_patches\n",
    "\n",
    "test_results = []\n",
    "for i in range(nr_images_test):\n",
    "    test_image_predictions = []\n",
    "    for j in range(0,len(test_image_patches[i]), 500):\n",
    "        if j + 500 >= len(test_image_patches[i]):\n",
    "            testing = test(test_image_patches[i][j:j+len(test_image_patches[i])])\n",
    "        else:\n",
    "            testing = test(test_image_patches[i][j:j+500])\n",
    "        \n",
    "        test_set_predictions = np.argmax(testing, axis = 1)\n",
    "        test_image_predictions.extend(test_set_predictions)\n",
    "    \n",
    "    test_results.append(test_image_predictions)\n",
    "    print sum(test_image_predictions)\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "print 'Testing time: {} seconds'.format(t1-t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check vessel images\n",
    "#result_image = createVesselImage(test_results[0], test_mask_matrices[0], 32, \"patch\")\n",
    "\n",
    "#plt.imshow(result_image)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57621L, 6L, 28L, 28L)\n"
     ]
    }
   ],
   "source": [
    "#outputlayer1 = lasagne.layers.get_output(layer1) \n",
    "#outputfeatures = theano.function(inputs=[X], outputs=outputlayer1, allow_input_downcast=True) \n",
    "\n",
    "#features = outputfeatures(all_test_patches[1000:58621])\n",
    "#print np.shape(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57621L, 6L, 28L, 28L)\n"
     ]
    }
   ],
   "source": [
    "#print features.shape\n",
    "#for i in xrange(6):\n",
    "#    plt.figure()\n",
    "#    plt.imshow(features[1,i],cmap='gray_r',interpolation='none')\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights\n"
     ]
    }
   ],
   "source": [
    "def save_weights(filename,network):\n",
    "    with open(filename, 'wb') as f:\n",
    "        cPickle.dump(lasagne.layers.get_all_param_values(network), f)\n",
    "        cPickle.dump(losslist, f)\n",
    "        cPickle.dump(validlosslist, f)\n",
    "        cPickle.dump(test_results, f)\n",
    "        \n",
    "def load_weights(filename, network):\n",
    "    with open(filename, 'rb') as f:\n",
    "        lasagne.layers.set_all_param_values(network, cPickle.load(f))\n",
    "\n",
    "project_path = os.getcwd()\n",
    "filename = project_path + '/Project1_weights.pkl' #'C:/Users/Atte/Desktop/Capita selecta/8DM20-CSMIA-group-3/Project/Project1_weights.pkl' \n",
    "network = outputlayer\n",
    "save_weights(filename, network)\n",
    "print(\"Saved weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
